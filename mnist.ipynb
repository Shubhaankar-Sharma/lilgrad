{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST training and testing run using lilgrad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from lilgrad import nn\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])\n",
    "\n",
    "# normalize \n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# transform y_train to one-hot encoding\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = nn.NeuralNetwork(784, 10, 2, [512, 512, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch: 0\n",
      "epoch: 0 loss: 2.5215207209721973\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.5138135838253444\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.506206619694597\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.4987045180764667\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.491306569736037\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.484006717273702\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.476812989086543\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.469724479422636\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.4627416601061656\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.455847100911287\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.4490474747860875\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.442354048508506\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.4357565376192127\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.429223278742506\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.4227422560712357\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.4163309731697193\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.4100023641042174\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.4037300082199464\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.397521884794536\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.3913849330075445\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.431873611348719\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.4265942089168977\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.4213932345552616\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.416254444285827\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.4112043082877626\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.40622413075504\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.401284210945267\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.396404931560214\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.391591103329885\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.386852937325024\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.3821665856533443\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.377514990397236\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.3729056645637145\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.368357128168409\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.3638551552374\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.3593883587627187\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.3549661887943225\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.350576563805496\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.346227161097708\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.3419177635984085\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.329922667954292\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.3257108487105427\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.3215119275060796\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.317345508169788\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.313216831298406\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.309114380005255\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.305031113890295\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.300970406659607\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.296928708885116\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.2929247837331994\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.2889435832885203\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.2849830893883762\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.2810494309084453\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.277138756043556\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.2732577750999328\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.2694036947918304\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.2655702169682703\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.2617606435634983\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.2579682183877186\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.2541964927471074\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.317896084116459\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.31392539095642\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.3099828443069526\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.3060606127195524\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.302167264167985\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.2983079891490403\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.2944734096185924\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.290649946792309\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.286850266970017\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.2830674185057305\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.279306542708728\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.2755688587260243\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.2718579535038597\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.268175358973746\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.264512239471877\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.2608694715125863\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.2572429007138926\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.2536417090359717\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.2500645035739257\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.2465107669966535\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.268918713249073\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.265848236291741\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.2628033812038266\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.259767030922254\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.256747703804456\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.2537529074043543\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.2507758658244574\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.2478095005087173\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.2448526602150722\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.241910561465056\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.238979895767103\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.236058692931109\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.233150125540732\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.2302576170048027\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.227372642219939\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.224494885759718\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.2216355280509377\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.2187969251434723\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.2159662551271793\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.2131455824071082\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.2602526286599556\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.2564730675836784\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.252712153817519\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.2489755215023477\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.2452601688895255\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.241562099457725\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.2378944409162056\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.234256570896406\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.2306210728910956\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.2270117782156635\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.2234175476626925\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.219838801159654\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.2162671825415208\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.212713958127616\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.209174897770353\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.2056431555845712\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.202121331211428\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.1986145507132315\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.1951369325011885\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.1916735409474413\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.2014029313420647\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.1978653824529557\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.1943432690751568\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.1908411856856755\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.1873478441267924\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.183871890733769\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.1804164071515943\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.176976854734925\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.173553503022567\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.1701473995672322\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.1667591766894327\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.1633916510470472\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.160044859640823\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.1567199831443213\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.1534024673284744\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.1500890184019195\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.1467997770990523\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.1435189794680456\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.140242352554482\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.136979065685742\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.1135257660883626\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.110419614410853\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.1073309199370645\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.1042638159023346\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.1012149949506216\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.0981802903790294\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.09516065037586\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.0921506630238893\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.08913633178791\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.0861405557894517\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.083142164376861\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.0801425293642977\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.0771363260105176\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.0741412761555433\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.071161529741807\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.0681989837865933\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.065247205063279\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.0623153605280793\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.0593959239703246\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.056491966258226\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.170849200577821\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.1685444753185807\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.1662486391018465\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.1639625286995683\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.161684397963997\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.159407342252773\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.1571285112136254\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.154853283007865\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.152586013765105\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.1503233585415344\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.148063107663542\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.145806709134441\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.1435504837379327\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.141293697414265\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.1390423612815814\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.1367988734610144\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.134563090576332\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.1323331378253934\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.13010864185757\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.127886127643757\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.1201059965354903\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.1153745598194806\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.1106911818498353\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.1060660436616043\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.101457303662454\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.0968901390579404\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.092358514417871\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.0878486874938327\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.0833734698561273\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.078932451446491\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.07454883852031\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.070243607557681\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.065991426475614\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.06177816786383\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.0576173200719383\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.0535213341574847\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.0494764721633016\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.045475964935529\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.0414999378074854\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.03756497780795\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.113230521212607\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.1089549515759085\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.1047049589396662\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.1004977932002507\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.0963334494759396\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.092218734071192\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.0881521320767935\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.084123061192912\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.080126599854722\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.0761765133673986\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.072274132494942\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.0684108521685434\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 2.0645752397901584\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 2.0607705408031425\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 2.0569855910218786\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 2.0532210258130057\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 2.04947677873918\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 2.0457625511530324\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 2.042071182146338\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 2.038410322786123\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.031694331837648\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.028814636853755\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.0259438467336603\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.0230808056838416\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.0202300066511523\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.017394770731057\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.0145734426309554\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 2.0117634709852483\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 2.008959825830222\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 2.006172977418654\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 2.0034139713347194\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 2.0006752658789018\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.9979503954073006\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.995236296208588\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.9925391813853426\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.989849186614817\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.9871660058886902\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.984486088115402\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.9818066965475505\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.9791375499899142\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 2.018112675077371\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 2.015116843114411\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 2.0121303912313224\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 2.009154966413765\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 2.006184670602018\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 2.003223287657063\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 2.0002717263809147\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.997338849739411\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.994422519644857\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.9915191673163073\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.988624925642041\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.9857442185046372\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.9828773887342304\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.980029631073967\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.977196597743338\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.9743836859834052\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.9715800409614936\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.968783471898523\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.9659903961162535\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.963205403113784\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.9814852491931922\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.9779463667638848\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.9744242993045458\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.9709227137472276\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.9674349737462382\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.963959174646257\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.9604941695142588\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.9570516991109117\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.9536278160045002\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.9502202760679455\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.9468280231535293\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.9434556937810827\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.9401017990588931\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.9367553686894752\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.933420309000888\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.9301015723935357\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.9267995933987323\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.9235090602092288\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.9202210695620798\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.9169471710067367\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.927994886697194\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.9253613534404082\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.9227296801095632\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.9201026645243846\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.917484443073584\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.9148745247253738\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.9122718918440307\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.9096715483910118\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.90707233786109\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.9044898987651597\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.9019192411975014\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.8993645273598632\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.8968096169630537\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.8942677416837324\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.8917346682791254\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.889201753185829\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.886668845795517\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.8841274645140331\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.881584300725788\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.8790385950102149\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.953246612519116\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.950068273578737\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.9469034188632879\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.9437532239092483\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.940619360607262\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.937501602261181\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.934407658334724\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.9313258483741396\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.9282527899955133\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.9251839348784952\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.9221208141627435\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.919072937279445\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.9160354835661186\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.9130046822732314\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.909988016436013\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.9069836922705181\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.9039839681492308\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.900994778391819\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.8980135490000523\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.8950391334594143\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.8118871357392399\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.8083840902701458\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.8048940550510104\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.8014213259682341\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.7979711497712283\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.7945404798844484\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.7911246870404511\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.787727601153048\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.7843557141001631\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.7810003576575753\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.7776588230813104\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.7743301327280907\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.7710217387856968\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.7677185120175642\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.7644324940390463\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.7611608294532581\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.7579012873807298\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.7546515668346652\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.7514025483399869\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.7481760085785039\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.8952345137330187\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.8917224922527236\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.8882245118274263\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.884752381302048\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.8812983437102666\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.8778631309706275\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.8744469891952962\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.8710539090745106\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.8676775189371426\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.8643186594896044\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.8609767201853824\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.8576469951755927\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.8543285849465332\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.851024211156259\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.8477344343012716\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.8444634813720047\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.8412086420223694\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.8379714468107953\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.8347537654618804\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.8315545846459815\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.8799777366472532\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.8770811536319254\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.8741992839595758\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.871337451264146\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.868489665808443\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.8656425471065006\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.8627978878526057\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.8599707258162161\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.8571480759368821\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.8543390552278711\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.8515438584442183\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.8487586392097652\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.8459842433259506\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.8432248669495421\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.840482894746768\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.8377534190734601\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.8350391149888141\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.8323378422417471\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.829634051755452\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.826935761602548\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.8435577435798898\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.8403931537086147\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.8372357904793173\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.83409568575888\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.8309716723277214\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.8278558714035706\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.8247459136608588\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.821645522589309\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.8185609779154204\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.8154896059673091\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.812437485940222\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.8094001865559486\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.8063768281378758\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.80336582990703\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.8003619721581112\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.7973625801851036\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.7943667581008618\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.7913849145009233\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.7884260416000162\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.785482398494857\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.718959889555491\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.715698696204894\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.7124713224322243\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.7092655716228675\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.7060658846573684\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.7028862812361913\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.6997288273361864\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.6965962073295513\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.6934850468080918\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.690388931998391\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.687315794600417\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.6842716609844004\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.6812467671295435\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.6782411703749207\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.6752491172719943\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.6722686894855194\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.6692998486971893\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.6663469208427821\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.6634079561720467\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.6604857237075354\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.8402031041328726\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.8367441016953776\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.8333074837557524\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.8299056483907494\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.826521899325435\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.8231676997853703\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.8198397102556707\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.8165412307335642\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.8132699399839605\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.8100208611665463\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.8067856712748784\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.8035741603999984\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.8003887588431098\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.7972335852519652\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.7941140988919175\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.7910080874609218\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.7879247795898383\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.7848558219339838\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.7818073655673807\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.7787798555922127\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.7102997862776739\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.7067642837972394\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.7032470411568659\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.6997468300786953\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.6962672621336539\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.6928157872364449\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.689393289316377\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.685988152651496\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.682606955757957\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.6792442863239465\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.6758973990845916\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.6725708872588836\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.6692604695223783\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.6659586686988321\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.662678546112232\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.6594092922445607\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.6561492956712645\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.6529030597319028\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.6496712499103143\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.6464535896108998\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.7550568341899857\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.7520941587741934\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.7491528889470251\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.7462447329358295\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.7433534767092551\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.7404857967042358\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.7376387058187315\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.7348115739384413\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.7320036437329343\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.7292147168661613\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.7264423250546703\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.7236858785111353\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.7209452677278791\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.7182174180188237\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.715502602591131\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.7128089239251234\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.7101326700240431\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.7074734444414137\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.7048264811040301\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.7021993347958415\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.6920550955509357\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.6894236756701113\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.6868067417198893\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.684203667832789\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.6816130718611584\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.6790289714863362\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.6764651247659481\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.6739165040179647\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.6713820022049737\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.6688563507281928\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.6663401675326357\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.6638281065784077\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.6613293800167526\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.6588414543224805\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.6563706694464468\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.6539121375544328\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.6514639698179545\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.6490236772099764\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.646593465497465\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.6441692452207932\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.7013576638795833\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.697606582673833\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.693888564683102\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.6901967211838573\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.686545275669742\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.6829318477109891\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.6793628356627741\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.6758282716207822\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.6723322509122538\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.668859780722289\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.6654252689909739\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.6620254302297568\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.6586511208446368\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.655291722767899\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.6519521715152357\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.6486344040082357\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.64534082285809\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.6420695213992553\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.6388158517091347\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.6355838640891482\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.645905185729463\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.6431695548057832\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.6404437836342147\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.6377299294562706\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.6350262617656246\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.6323287439072505\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.6296428888945744\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.6269667096681477\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.624305626929967\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.6216614299739556\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.6190294658567743\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.6164062456536648\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.613795539229435\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.6111885497570313\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.6085873835595872\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.6059937115970486\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.6034044834648542\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.6008232833202394\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.5982478355493168\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.59568010172184\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.608310692035786\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.605603505212025\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.6029111389870674\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.6002413490068133\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.597588192203919\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.5949556768627298\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.5923369631033863\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5897289991867725\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5871473394141695\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.584586634805852\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.5820515955910777\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.5795388110511328\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.5770439935368432\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.5745633103049952\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.5720899844214602\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.569632388329509\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.5671903482627187\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.564769176795279\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.5623605048406903\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.5599654835768433\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.5415737673786998\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.538427844531925\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.5352993017972825\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.5321881601035563\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5290942620894128\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.5260226032335895\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.5229645369522835\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5199189366221386\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5168824978905224\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.5138581370602497\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.5108468898292124\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.5078520901945087\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.504868558296066\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.5018976296067907\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4989460491163786\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4960031726368972\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4930710551027673\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.4901540218086775\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.4872459165968133\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4843529498172154\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.5917686069038577\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.5887616054808844\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.585768118030924\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.5827936439008474\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5798368949251498\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.5769004780880824\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.573983144295388\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5710844562506419\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5682032626224736\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.5653437591853514\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.562505548629548\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.5596851796944005\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.5568826443603792\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.5540984609652675\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.5513289519672826\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.5485736718806136\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.545836073336476\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.543112616236109\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.5404048497533838\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.5377075171845587\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.5262640666479683\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.5232960095617507\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.5203453812139167\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.5174209676713266\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5145117120347849\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.5116189224099161\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.5087416021942128\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5058766087894155\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5030285031631552\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.5001958426170212\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.4973755455650744\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.4945696191843103\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.491790484882111\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.4890277342823097\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4862800483153162\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4835486877189528\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4808285844235112\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.478122925475781\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.4754291670263369\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4727458200792107\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.5149949631461164\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.5120275012580877\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.5090795887318178\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.5061506855034668\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5032449628699265\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.5003643952224621\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.4975040281761856\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.4946605729802134\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.4918398527702292\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.4890314061898018\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.4862360749267451\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.483457602430583\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.4807003359111388\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.4779632951824855\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4752457221929918\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4725512035849335\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4698744346868173\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.467208456850285\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.464554772664663\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4619174867842812\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.5253759972967662\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.5223430936742046\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.5193405126316706\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.516365496518548\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5134141218676394\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.510487929034845\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.5075897835956709\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5047188302915178\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5018719380815115\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.4990416463329477\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.4962303304818525\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.4934385527948209\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.4906606864487706\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.4878969270288782\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4851488660268426\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4824184509927945\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4797089657899332\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.4770224783239863\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.4743553609212579\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4717077727837284\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.4525214966534048\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.449339388082885\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.4461939972904467\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.4430837466235515\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.4400043234405102\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.4369373785929165\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.4338974663460355\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.4308759932247326\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.4278854785476225\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.4249199197602127\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.4219745607657388\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.4190624946951078\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.4161794103477043\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.4133191541457664\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4104868823648578\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4076880450548064\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4049191893942128\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.4021744751590646\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.3994547169937979\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.3967618561072839\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.53749213758395\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.5346230930184737\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.5317772546663408\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.5289513863522077\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.5261538639986254\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.523378039278267\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.5206229993225968\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.5179021005242053\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.5152021351666733\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.5125172919159877\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.5098502549707482\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.5072038728581654\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.504573438715688\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.5019613849924986\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4993630419304602\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4967774294504776\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4942022670728137\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.4916433617618567\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.4890992944790415\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4865786341515517\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.2799523485896773\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2771098594282764\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.2742829772247997\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2714743618690245\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2686874374563244\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2659216788888896\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.2631728924047687\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.260440825492563\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2577338153947135\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.255042668884398\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2523613848571742\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.249693299817955\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.2470386581043786\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.244399573084228\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.2417740669863495\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.2391543533456812\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.2365465985675468\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.2339539319434008\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.2313798813808225\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.2288171450917538\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.3273979276225507\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.3241246695591167\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.3209039993359881\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.3177234529459338\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.3145811428016723\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.3114739500376287\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.3084065838374703\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.3053868531961315\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.3023992193502019\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2994402618207679\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2965083775776827\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2936153189601267\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.290754294480062\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.2879201804464893\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.2851109131223444\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.2823265671510171\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.2795663671575168\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.2768296957371332\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.274112931734775\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.2714189166623835\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.491769306659084\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.4881602632111082\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.4845959203227208\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.4810662551635576\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.4775871413176431\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.4741627865125986\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.47077714369604\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.467428367613875\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.4641225304676526\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.4608527692018414\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.4576115870307544\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.4544029018323246\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.451221122185145\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.4480652741445115\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.4449381370354333\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.4418414362126075\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.4387709266376125\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.4357276727722519\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.4327162300749046\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.4297257613047645\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.3162478567552016\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.3126251551145258\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.309059275616949\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.3055525453471954\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.3020930678441718\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2986751571502184\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.2953035687978485\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.291976205370287\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.288689340490028\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2854357219693693\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2822220063543677\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2790449290893071\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.2759021409117537\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.272799377372037\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.2697296934245181\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.2666917809447806\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.2636911239699327\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.260720086167916\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.2577751786566858\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.2548630673331913\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.3072619206149683\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.304333410347843\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.301437562709078\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2985790642740205\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2957472474649339\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2929424232461226\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.2901709006973574\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.2874254952279607\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2847053466431086\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.282008039049237\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2793320695327859\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2766805760925228\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.2740502175263702\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.2714481475075152\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.2688685018654082\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.266307308196557\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.2637639410488912\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.2612388311232463\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.258732932685068\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.256250395956393\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.2682001851139089\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2654375694919584\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.2627027827360024\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2599967286073694\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.257314555923801\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2546584652192125\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.252027719201032\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.2494241743108279\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2468472968338045\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2442927964283588\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.241754575777471\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2392366088052333\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.236746387959169\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.23427810343652\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.2318286537223992\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.229396704402541\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.2269812668963112\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.224587984332729\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.2222090055182262\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.21984575163011\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.230756207096785\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2279035428405278\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.2250895381011588\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2223119123014867\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2195747407938728\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2168699481852085\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.214203822782991\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.2115704032385692\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2089662615243384\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2063898189933866\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2038347499809758\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2013113677977891\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.198808921432741\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1963226988365239\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1938611724606232\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.191425125889464\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.18901739816083\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.186628719776473\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1842674177847454\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1819330192260231\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1490868584277236\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.146230165520891\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1433902966974727\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1405823790221408\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.137809313209626\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.1350640095249545\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1323418875978095\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1296468355560332\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.1269772251198902\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.124337888064225\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.1217288580541283\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.1191428173998423\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.116573952310075\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1140284147893553\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1115013142820032\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.108993637766114\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1065077511636159\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.1040416751379458\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1015954384692077\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0991722826874857\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1829008430515628\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1802202373795454\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.177565491865469\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1749329536137163\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.1723318554557705\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.1697529439832342\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1671891242496275\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1646423709267766\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.162115314537326\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.1596089477313067\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.15712582382019\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.1546639795665428\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.1522141557880525\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1497850712398414\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1473771327826563\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1449781309894018\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.142593054962047\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.140223518055581\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1378655747271056\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1355228009277418\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1716023404852538\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1693591738518607\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1671293238471225\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1649120951906822\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.162705237506377\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.1605108537908975\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1583270304297253\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1561527906833668\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.1539941855170261\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.1518506891741414\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.149725203029385\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.1476188065634956\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.1455314494431232\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1434600441950153\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1413992894892329\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1393498201241579\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1373121979509964\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.1352881395628955\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1332749638540376\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.131271957315864\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.23033601502665\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2277606706531898\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.225208629725978\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.222679582437221\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2201714657568574\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2176854215362547\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.2152196419797487\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.2127729280519688\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2103545442950212\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2079549648803727\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2055730863128393\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2032126093252835\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.2008693601270033\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1985475104997196\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1962438043606278\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1939565724406433\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1916812517100006\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.1894160579614474\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.187162118255645\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1849216508546307\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.109745593727257\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1077624604560181\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1057921373838049\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1038379375801073\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.101900464147528\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0999742758124722\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.098061047540405\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.096159278029349\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0942682956716245\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0923862045008148\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0905156676119476\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.088654100412783\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0868007645629105\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0849576588217902\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0831219190449266\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0812975624585537\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.079483607145012\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0776790830582526\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0758792462435731\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0740864653146627\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.9176697652040623\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.9153616491141985\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.9130846718495386\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.9108365295478489\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.9086143524964373\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.9064250455878717\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.9042639867500073\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.9021309884409476\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.9000271703322512\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8979454590825767\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.895885277061178\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8938444457234087\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8918263328807108\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8898300208500014\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.887853523653513\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8858964333759689\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8839566278644203\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8820330417174693\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8801239771038235\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8782292605825773\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0904157689427174\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0879089335458936\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.085424351294081\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.08296085790644\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0805196423274008\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.078100727027373\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.075704514160655\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0733283249124967\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.070969914312001\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0686270151713781\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0662990050974153\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0639890013753077\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0616962513322028\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0594197597879265\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0571564423340603\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0549039537629783\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.052662462721551\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0504389024575511\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0482344394802658\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0460398579654702\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0860981306627577\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0822256935020724\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.078441913808553\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0747475269514448\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0711476392019086\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0676219631410844\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0641682461444795\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0607743976981578\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0574525391537717\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0542001068264037\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0510131560795515\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0478817323985365\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0448041404160193\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0417774787628424\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0388008994317368\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0358664987037982\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.0329821396819023\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.030157906457967\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0273698817574677\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0246162606779978\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.110187338645803\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1077430409019944\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1053411467780598\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1029738460462142\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.1006381636981057\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.098334994106532\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.096067749316934\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0938259355577347\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.091606612351541\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.089407002965275\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.08722704956044\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0850701445141704\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.082935045463016\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0808208699875594\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.078725707045776\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0766488513476404\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.074593988582067\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0725583185273968\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0705400020637228\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0685396252026678\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8935697435914953\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8916468810266268\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8897362646265521\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.887837584844094\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8859512344823308\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8840802538303849\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8822220923633943\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.880378656740164\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8785492330371709\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8767315384888599\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8749240713693274\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8731279939026595\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.87134430199664\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8695698944258943\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8678101515776577\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8660584375906077\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8643135372788258\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8625757554332172\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8608449565356996\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8591227964192911\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1504857653966902\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.148346890647645\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1462195931766541\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1441065763544813\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.142009633006785\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.139924704107583\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1378512368545541\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1357907677790084\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.1337401131977196\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.131697801479065\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.1296666373216944\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.1276455412081983\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.125632609166107\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1236342159394361\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.121649525072913\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1196748997581178\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1177132198044486\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.11576224014861\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1138180827224171\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1118822218548394\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.2275439215171167\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2253121412432018\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.2231011272584607\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2209139378964498\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2187481746656126\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.21660444000198\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.214485453597851\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.2123843238443655\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.2102999519483497\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2082339881688453\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2061881903964335\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.2041565294268055\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.202138199372432\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.2001338491909561\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1981411407748133\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1961655066575738\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1942041503952072\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.1922561997727033\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1903199770253234\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1883968293458413\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0493837703208664\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0461563861203462\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.0430358417859975\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0400155422173658\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0370971144316556\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0342731831395175\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0315252275524458\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0288398495856113\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0262243383124134\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0236816116846543\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.021209263754539\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0187999158928442\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0164588713575238\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0141761291500686\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0119464025295684\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0097571660231406\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.0076146232459027\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0055233842516635\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0034733506273912\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0014641816967769\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.039415176133428\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0372979826447142\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.035200772196177\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0331262087828006\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0310685949481333\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0290285083186022\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0270018094120363\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0249868693798034\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0229883367740968\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0210035663565782\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.01903282354411\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0170818074239807\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0151460702166832\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.013225598822292\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0113190943097456\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.009424832968409\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.0075391283683661\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0056704049768443\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0038168173563584\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.001973733586344\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.2752571569351896\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.2728618706978638\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.270499448929943\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.2681703374647832\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.2658719684150892\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.2636030800493079\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.261365110142851\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.259155646139396\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.256970326403177\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.2548103694531685\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.2526744282044358\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.250559695769659\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.248466514964112\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.2463939044577952\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.244343406656773\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.2423123127185896\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.240300733831757\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.2383099731296048\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.236338817083972\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.2343874299217272\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1852132961601998\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1827223339470767\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1802602323487519\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.17782877060479\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.1754204202850913\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.1730373833616938\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1706836138469507\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1683538496651469\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.1660489741043596\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.1637686764440538\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.1615073228035762\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.15926953173485\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.1570532417780544\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.1548547065677515\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.1526677348420282\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.1505008539203574\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.1483557009304624\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.1462291530833997\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.1441187388574732\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.1420234068108124\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1415652799478866\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.137637844658067\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1338007428666064\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.1300496286279949\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.1263788501612115\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.122782459656962\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.1192612002185445\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.1158183573987328\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.112438851990984\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.1091285621133342\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.105882661959033\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.1026872609508147\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0995464312079717\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0964517398402582\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.093406926129909\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0904052418788597\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.087447472567332\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0845270355565826\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0816468725909854\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0787980767741847\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0728803685281665\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0695197766636206\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.0662484593734822\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0630620731077316\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0599502716445932\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0569045289462118\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0539122546229946\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0509827586547984\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.048115310449927\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0453120934327709\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0425661686098406\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.039882367552909\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.0372510874484724\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.034670055354514\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0321369250043146\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0296533391375324\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.0272118488761626\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0248111624143297\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0224483734224568\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0201213674509404\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.1093618541495607\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.1056344573327357\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.1019863015744171\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0984207657951433\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0949369463599306\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0915355870734271\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0882086547700474\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0849445107546627\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0817381981072962\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0785871105494724\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0754963070602144\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 1.0724639494350583\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 1.069484300966721\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 1.0665580597185378\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 1.0636791578529774\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 1.0608443731141497\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 1.0580570265520393\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 1.0553203403457592\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 1.0526277021324\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 1.0499766428701256\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.9275763498547553\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.9247937306611738\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.9220647148773974\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.9193892704714762\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.9167619699409539\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.9141843734969033\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.9116562041353065\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.9091694806280122\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.9067268170912965\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.9043316496663394\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.9019772987845813\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.899661732834813\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8973849515768669\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8951448070700423\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8929428262165346\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8907723512657648\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8886297588089729\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8865167468483249\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8844313598915217\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8823731298539008\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.9787781560554972\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.9756965196289261\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.9726617228983008\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.9696784306886037\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.9667495130386483\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.9638661588797033\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.9610193137364592\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.958214239183303\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.9554460874084653\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.952720203610238\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.9500396943780725\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.9473945445763517\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.9447845164401498\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.9422136434989319\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.9396707835484059\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.9371607853855529\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.9346802237495486\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.9322256009048688\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.9297960447363114\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.9273926937374602\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8812393070686393\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8782685488762711\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8753643216917925\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8725235637530767\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8697436193248955\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.867020243704689\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8643556240422507\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8617486670123544\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8591922249801263\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8566846204321142\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8542247536891341\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8518094371573919\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8494403578251953\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8471184411233312\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8448402489710001\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8426031844051958\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8404015558140889\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8382366870318574\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8361059217707529\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8340121921404762\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.021216692688394\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0187480838544198\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.0163446807842536\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0140029041130258\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0117120399247597\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0094700982770493\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0072740893609238\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0051220236766985\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0030094615734595\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.000938412105341\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.9989063922962893\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.9969120180194764\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.9949540479869159\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.9930233973233804\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.9911221227322184\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.9892472863340471\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.9873986858879653\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.9855763963414196\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.9837777395367293\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.9820016740313369\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.9425724227454342\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.9405687553739526\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.938591375064744\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.9366428315908105\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.9347186829554208\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.9328146557331641\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.9309395467639558\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.9290869472534253\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.927255721188336\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.9254478319045546\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.9236612186685305\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.9218947792822987\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.9201444307255459\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.91841455315176\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.9167028154695287\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.9150062738018847\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.9133231010936429\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.9116532126329941\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.9099963265697804\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.9083521290744903\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7421568786040724\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7404036541482639\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7386779873213513\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7369847427750451\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7353107062100419\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7336551458128202\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7320187788567664\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7304019994704904\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7288050685018774\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7272237857340484\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7256553083814872\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7241004748956281\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.722559718493855\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7210310478032214\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7195136321709635\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7180069347610305\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.716514563652896\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7150317417796144\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.713558804258208\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7120990659721786\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.9182164964768624\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.9147768318127112\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.9114463492832058\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.9082264088957508\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.9051074621135538\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.9020958048960555\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8991735632095931\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8963369704509716\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8935838017362971\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8909183177494382\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8883155009844241\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8857723406089988\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8832880010311773\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.880869550463186\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8785134803774595\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8762113953242535\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.873946455827933\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8717320215635067\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8695593442626995\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.867430539910099\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0491392108201134\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0436377714017007\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.0383907296278088\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.0333552986114423\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0285138835830236\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.0238530486349817\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0193572749842001\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0150418795236047\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0108640770971409\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0068343568645233\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 1.0029467908580272\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.9991804952830403\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.9955235269327056\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.9919797916419295\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.9885482220795265\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.9852201680748568\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.9819939508525642\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.9788592452697236\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.9758195813398232\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.9728527056243287\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 1.0271329312291844\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 1.0238381733563093\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 1.0206257451432004\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 1.017503308666127\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 1.0144603584695036\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 1.011499989409133\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 1.0086263286142043\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 1.0058237605805747\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 1.0030957685039903\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 1.0004391824017216\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.9978463039280623\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.9953186005594701\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.9928492696236939\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.9904374973756723\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.9880797256836882\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.9857698121876787\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.9835014256830918\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.9812731713532132\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.9790824659456296\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.9769310361899138\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7487279111148162\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7466514928194998\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7446180492024599\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7426312073454355\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7406807812358838\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.738768999838666\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7368932386995747\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7350546852377954\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7332470538344317\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7314762661627825\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7297346072366651\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7280204740272389\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7263318276179065\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.724666965157643\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7230277455381999\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7214130023393084\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7198287482455044\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7182685257149457\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.716727518049108\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.715205242116401\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8354691672085013\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8336857835807026\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8319242810047734\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8301820400404644\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8284561759901733\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8267486507276823\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8250589173656684\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8233850528633557\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.821729081059348\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8200889083933152\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8184619855950819\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.816849904632002\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8152517369746479\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8136694571813567\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8121010243474602\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8105467952180357\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8090050425642578\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8074749284316963\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8059573804051758\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8044521839037029\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8875101393183953\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8852023933952979\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8829396246009021\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8807267226436211\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8785573319349382\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8764354336596336\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8743505308508144\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.872301051082564\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8702892549278392\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8683152771937375\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8663748862037854\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8644613788495805\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8625751388329592\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8607148474523075\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8588816785765985\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8570747279941724\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8552925343690048\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8535337755539396\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8517985665984711\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.850086978742234\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8761652071340722\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8734454262899322\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8708043498262453\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8682402804507141\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.865750450897061\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.863322443634836\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8609529989686052\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8586353413095007\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8563715587612148\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8541649486018539\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8520172343384608\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8499203222938562\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8478693654528807\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8458671920223626\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8439026489792083\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8419731250763896\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8400782491019652\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8382164198678073\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8363834813169534\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.834578365052745\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8606611634403479\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.857670865597506\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8547350998270553\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8518558610792438\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8490289091487851\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8462536362119336\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8435242445791327\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8408404525199376\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8382026248327752\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8356073293661688\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8330513232110648\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.830537846446497\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8280632685957376\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8256236805739372\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8232166936072497\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8208387280274911\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8184957281716282\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8161843016171453\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8139015305108224\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8116484281543062\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7415427043856507\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7381864331352528\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7349423733680865\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7318013730872829\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7287558930544538\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7257948575079416\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7229190750854526\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7201191734398418\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7173896527558996\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7147249664739315\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7121256293211555\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7095889891077627\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7071104063535408\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7046859234396085\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7023092151369803\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6999860915213191\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6977154879932654\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.695486518163928\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6932959197455473\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6911443298857469\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7668598617236645\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7637281198049426\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7607022434821834\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7577799610871907\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7549361867603106\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7521872112696588\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7495271643011712\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7469518756870536\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7444532861538338\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7420257961836614\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7396724663024046\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.737380286271857\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7351457810660267\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.732965799715203\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7308395743174452\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7287644721008427\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7267373784093308\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7247572084536135\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7228239013140912\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7209327367228038\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6857337908683345\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6838399237140989\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6820049442400158\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6802229704566147\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6784905570847419\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6768028258971326\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6751603662698021\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6735596884458048\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6719981006000204\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6704710408639738\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6689755036476075\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6675128580299987\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6660740979600294\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6646655811452526\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6632863208026396\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6619353874795765\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.660610258726597\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6593110142031777\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6580326174766749\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6567738758356615\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7496470670122165\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.74683300101199\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7441347058091734\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7415362601098154\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.739034313395435\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7366138446011137\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7342692470921187\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7319948417843869\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.729790238591535\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7276480112231776\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7255647670250223\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7235440011503915\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7215779910434964\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7196571898164568\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7177776170859397\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7159312084943924\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.714125249004911\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.712356040009906\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7106177735530783\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.708911095835735\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7633694968252449\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7605357327663078\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7578140521666044\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7551965410776531\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7526825164204247\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7502707560956743\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7479483643596413\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7457145104630541\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7435558932599831\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7414656266548166\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7394399172532173\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7374760081769107\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7355756248300457\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7337305963528159\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7319373541250289\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7301941366063707\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7284965387439815\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7268398221140319\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7252191177227271\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7236334362253696\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6720227886118373\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6674715865198\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6631977505102306\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6591748110792044\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6553768499456658\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6517980730703679\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6484015934433123\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6451751623602529\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.642097209060581\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6391568010091966\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6363490375908614\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6336596794952896\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6310773578980076\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6285986686973191\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.626214994350812\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6239225276181413\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6217102687931344\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6195714527203866\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6175057417098243\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6154993162067309\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6268363560598915\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6237702849871714\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6208277084250242\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6180001807615458\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6152739475704047\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6126449952661943\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6101044520865007\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6076447548783948\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6052615045272338\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6029491183993143\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.600708591071471\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5985307937460338\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5964109761768127\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5943436908940976\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5923273046316581\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5903619678177467\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5884456554118593\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5865736576350071\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5847421188587772\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5829549316117741\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6059822048089663\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.604198139694743\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6024569022583678\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6007527627984871\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5990856419068725\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5974523546942979\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5958484777124948\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5942762629666751\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5927378030774525\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5912349183067592\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5897600895617604\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5883108767913579\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5868861812254473\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5854841756778997\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5841049353683607\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5827456455755682\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5814028825403333\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5800800172846253\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5787782766474079\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5774965377027916\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7874065621337789\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.783861639422351\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7804529490118979\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.777174302925064\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7740217205824307\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.770991424991055\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7680707963152347\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.765251765883097\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.762521248443081\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7598810010110202\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7573281384656457\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.754856483194859\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7524616289747269\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7501414525589127\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7478885911582722\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7457000951002519\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7435838478000731\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7415257962492161\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7395174726649982\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7375584890098709\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6915183030878574\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6896111093169699\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6877512899577589\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6859449265851933\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6841797638671564\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6824557263727928\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6807710676011506\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6791205572451162\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6775029400794057\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6759193822197139\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6743666552304234\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6728437700983886\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6713483580666275\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6698803619002718\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6684358499766474\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6670148668357374\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.66561749987072\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6642443069048094\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6628919556863189\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6615568727828528\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6122260112627795\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6105145853436496\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6088479109566718\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6072282072942039\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6056460845923609\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6040961755372495\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6025757845822771\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6010878389098321\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5996316064609754\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5982072150548808\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5968120106417898\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5954420339844033\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.594096854207272\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.592776264999762\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5914775342738945\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.590200817910106\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.588946733835067\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5877140861727397\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.586500640161338\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5853027436725381\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.59916941576127\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5973371271787431\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5955582834807094\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5938313523493093\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5921505944483179\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5905134420374658\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.588917048509742\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5873583900607995\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5858347522638396\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5843441701684751\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.582885266657933\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5814550051939588\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5800541346856948\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5786801793799865\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5773332951610961\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5760115266147425\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5747147822849418\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5734420404983954\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5721915607676464\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5709602320923008\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.70488750421502\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7019831792284756\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6991881943640748\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6964958021281915\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6938985288043042\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6913877223302849\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6889584852202647\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6866097346540214\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6843423703319725\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6821463402491067\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6800173325768247\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.677952957943607\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6759442844677425\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6739897417243619\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6720871902804122\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6702297411732557\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6684159916184835\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6666474950941191\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.664917420147555\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6632280507594905\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6937889222365434\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.691486382641515\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6892455207231244\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6870612350053276\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6849301291823152\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6828534618466668\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6808285138889881\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6788507389175613\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.676924792421109\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6750425141121389\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6732079252861092\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6714067186771275\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.669639317796767\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6678984658975137\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6661870739306289\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6645017468553205\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6628430732779933\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6612098832102082\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6596014121881033\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6580153307071086\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6439309163379358\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6421099633747557\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6403314128281654\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6385905935695451\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.636884301030147\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6352101624457269\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6335686124167663\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6319617269621505\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6303840629675235\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6288304334949419\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6273030035138983\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6258014432006664\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6243282946440059\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6228783775599886\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6214495276539833\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6200427706631205\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6186535982314161\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6172826448980218\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6159291605629558\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6145924099367601\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8934476808599211\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8899366298320279\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8865230885829207\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8831981758080049\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8799606518365697\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8768082858941754\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8737434910206193\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.8707581049355817\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8678487005002703\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8650173012162385\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8622572997026019\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8595623466561257\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8569321399952584\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8543698308669638\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8518669293604564\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8494258322753199\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8470404087740881\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8447123835028749\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8424285763943131\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8401883274109068\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.811223415865262\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8090719897102174\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8069687636974919\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8049127813260675\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8028962366175727\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8009151033653372\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7989804801021384\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7970839871554543\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7952244257936524\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7933984282209273\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7916121984156739\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7898584748448095\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7881337970051389\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7864367289499063\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7847662241368447\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7831211190548157\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7815019600305693\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7799075675805334\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7783285354464526\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7767701160025522\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.738801702925616\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7366004792185754\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7344413550656421\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7323208018672293\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7302376890621314\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7281873859136407\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7261747812413905\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7241958197002952\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7222482632548621\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7203319257391962\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7184436084322027\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7165803010095093\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7147429110771895\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7129319674908042\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7111484703929831\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.709386816399675\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7076485047982788\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7059327144969489\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7042354225417058\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7025572953822498\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6740112640169403\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6718763742568169\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6698032403896073\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6677846888272899\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6658159247800444\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6638953719415508\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6620164298281793\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6601831634183333\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6583946483613637\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6566502947965592\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6549509926733941\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6532870997429787\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6516543200616173\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6500527464616517\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6484802942942886\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6469395693849149\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6454298934295678\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6439443847061068\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6424819402435259\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6410414929992303\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5915780318710318\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.589188573108256\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5868673881152513\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5846069275656331\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5824036989793254\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5802552531764871\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5781618483616775\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5761175200940936\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5741227144169473\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5721678578989808\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5702570244231664\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5683882819133298\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5665563619819641\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5647628632498252\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.563008557232725\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5612944791443957\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5596138016511618\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5579672500023461\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5563523812914316\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5547681336527082\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6404323936750311\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6384196352058771\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6364751967371765\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6345908580723927\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6327647491562673\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6309898525566595\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6292620109900342\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6275876179866207\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6259643936003445\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6243829764654132\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6228394887721767\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6213330286736582\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6198637493595425\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6184270937099172\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6170217917769312\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6156454660239852\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6142977642190741\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6129759128547049\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6116809149143884\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6104102070012387\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7234415825318452\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7206617447528769\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7179757321368995\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7153659466594395\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7128371388917569\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7103877539542803\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7080106685565707\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7056996859411585\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7034517587658714\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7012596364118162\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6991223980807331\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6970349257515418\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6949967837910249\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6930043270844493\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6910521308192993\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6891386806633168\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6872609804513479\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6854176129248133\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6836075622680493\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.681828461778635\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7782994060060957\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7741946646212157\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7702869268017825\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.766540806509717\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7629600553629124\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7595237598736526\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7562378792584918\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7530800327902091\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7500407371886775\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7471125744999785\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.744284219963423\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7415637077253903\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7389470404526153\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7364178582087396\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.733970177096765\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7316085644304609\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7293212346801154\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7271075739486158\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7249572154769958\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7228623954015098\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8713823205445288\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8676749567890785\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8640712362261493\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8605573680845302\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8571178744838448\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8537538613507536\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8504659122078146\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.847238907207126\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8440859281984798\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8409986836143664\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8379761340433669\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8350202716658983\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8321246727284528\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8293001210902837\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8265318790333676\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8238099561611989\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8211373361680305\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8185114705067604\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.8159328674158994\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.8134018981513967\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7672324234194758\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7651732413588154\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7631587406323308\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7611903317471873\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7592594923119823\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7573658644397185\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7555080768848537\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7536830903688014\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7518894245630747\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7501280403207666\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7483976106788106\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7466975981800424\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7450261891544145\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7433784941839818\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7417541045786142\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.74015332853992\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7385692921410814\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7370043416246127\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7354594460196824\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7339331891620724\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6575331473530239\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6559122859185944\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6543288293264796\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6527799644242324\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6512633735550288\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6497787312698649\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6483242738875311\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6468973553398245\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6454961738233296\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6441191720414424\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6427634687899366\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.641428175709865\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6401124493666981\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6388163277686763\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6375402220983613\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.636281183141407\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6350385414865751\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6338110022122984\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6325991759851726\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.631401632410022\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8173664855048003\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8134027015622369\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8096525035049628\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8060991249223892\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8027235927886229\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7995052214816257\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7964271476433633\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.793488706847479\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7906716232300739\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7879719658584243\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7853715749584868\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7828601759070934\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7804306540933809\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7780802586625875\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7758066306921907\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7736027808415127\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7714590668815922\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7693701788156101\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7673347799945568\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.765352904600209\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7740285581648554\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7703160522358442\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7667779357254569\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.763402583712914\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7601825475248621\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7571104674553424\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7541758519312076\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.751342195828195\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7486139461630861\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7459876503144535\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7434622113263281\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.741030491413716\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7386695631002773\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7363793318350249\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7341685580267552\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7320286287871318\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7299589470804466\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7279533332520635\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7260014833060455\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7241005540312059\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6443585040120462\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6415446338605535\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6388328764747446\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.636214773550259\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6336790793044343\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6312288611822297\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.628867191407741\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.626583397645796\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6243704914003265\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6222262348039544\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6201505391682637\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6181320276163094\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6161675870552619\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6142571745747125\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6123930120456618\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6105742140783482\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6087978574779493\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6070611900222893\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6053597955141449\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6036933817510202\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6287620857359313\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6255975069699369\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6226116953669996\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6197789531549417\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6170899520050441\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6145387481806746\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6121217513043804\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6098246719403242\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6076441272722111\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6055578213043179\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6035593416190692\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6016426414683806\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5998015533605254\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5980299857536687\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5963199297615164\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5946705364270549\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5930759963471479\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5915329221185115\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5900394345276251\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5885935149203954\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5174841847506578\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5157382847533665\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5140483491685184\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5124112438572191\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5108257770548348\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5092914091546543\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5078055708466045\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.506363229937441\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5049628765793335\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5035997753669472\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5022731789707113\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5009806394996743\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4997211789630612\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4984955990398453\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.49729885167696897\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.49613086181350474\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.494990404088384\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.49387494523192754\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4927838915096591\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.49171556302748287\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.595960070246525\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5946978839168184\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5934552480806207\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5922300123885325\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5910220436890777\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.589831185503416\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.588656160402379\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5874954278636497\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5863467426804774\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5852141447012333\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5840990273421253\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5829959775596232\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5819050919530571\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5808246312213002\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5797572669156568\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.57870350932559\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5776613793825667\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5766303512095223\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5756143037258832\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5746061022885691\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7162713976026382\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7137814241709709\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.711365830115857\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7090197967172032\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7067408901916006\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7045236534216617\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7023675386891446\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7002731409822837\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6982365414976581\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6962544640769861\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.694321362818276\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.692436672636694\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6905948142911766\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6887975687065264\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6870440376929344\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.68532993223523\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6836515306771057\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.682007449601501\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6803936776316342\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6788119356084434\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.688248610812244\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6863232265443425\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6844383071361022\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6825932570427227\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6807887501515432\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6790171169453467\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6772762480171713\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6755669436865065\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6738859162276778\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6722313703582661\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6706017187730181\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6689956700308914\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6674115739828272\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6658502387305989\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6643130622035065\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6627924478874798\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6612902605722114\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6598078166473428\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6583403907369847\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6568891054306247\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7738529817874037\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7712386475955271\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7687108724170244\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7662614123871134\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7638823242897285\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7615708369639704\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7593214306543924\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7571332900576646\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7550013891318664\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7529222702892937\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7508922233656619\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7489116215861222\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7469744664265452\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7450802884036195\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7432242802564814\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7414043083967208\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7396295536993973\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7378953658142589\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7361993870886598\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7345340706318693\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6192553461154258\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6163759800193912\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6136337139189714\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6110207434877719\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6085245631592655\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6061354291149321\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6038458654991222\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.601649510752452\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5995357746311917\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5974998900450671\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5955381236710696\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5936466192553485\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5918196397057229\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5900636966352424\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5883584826055834\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5867019506013669\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5850903072899982\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5835200243960079\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5819890211047422\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.580495234585995\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7505913385673948\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7470820886187202\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7437567174444188\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.740593666139144\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7375796400517325\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7346899355699078\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7319323775609052\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7292891763425459\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7267502287420551\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7243024488212599\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7219432684525853\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7196706528451882\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7174889740569319\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7153817842450534\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7133396029292224\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7113593626181615\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7094331108295454\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7075594313480965\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7057337557182795\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7039511106226862\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7824704088171093\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7783315403600062\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7743789177771894\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7706074662034983\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7670035901792733\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7635544993919119\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7602520719976088\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7570848668714849\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.754041417500525\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7511213273826095\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7483142414799397\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7456068470574648\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7429851714466695\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7404407622188403\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7379803337424375\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7355968385733217\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7332853728221338\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7310430575498268\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7288614730856477\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7267434331593459\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7198135666296277\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7167932558502755\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7138636250035315\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7110055771084836\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7082473104023599\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7055764836212022\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7029886996815307\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7004816162917584\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6980482650629418\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6956839062373048\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6933897464790367\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6911583201200482\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6889834371021883\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6868629569083033\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6847956163920684\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.682781618217366\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6808149510781218\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6788919020897535\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6770082350030919\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6751660475508889\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.8892830049518143\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8815955881919233\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.874340122195119\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8674962531012567\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8610410104071999\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8549454680425341\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8491786729539548\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.843716785938373\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.8385360575895195\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.8336089923478194\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.8289190160074049\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.8244453612002851\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.8201853935818946\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.8161128432832815\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.8122266635679526\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.8084989022094055\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.8049190535159165\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.8014763837903045\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7981573157533857\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7949528048893153\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.828416633600882\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.8236877724412364\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.8192197505904222\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.8149776736057391\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.8109397496664292\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.8070908098358527\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.8034125032303737\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7998903702788829\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7965108904710043\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7932603568421236\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7901281309509776\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7871033745838252\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7841766523069988\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7813461933085788\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.77860116272453\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.775942855372061\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7733584953165145\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7708418332154306\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7683922034303846\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7659994207121656\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5564465842173045\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5543525910584474\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5523233514688903\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5503500146337424\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5484362804997766\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5465774470203701\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5447687757010954\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5430129659902524\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5413022451488937\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5396339245743835\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5380086172138067\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5364192540728986\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.53486562449314\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.533350937385685\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5318741086207321\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5304307114584311\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5290182698412278\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5276323590423997\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5262725239218449\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5249377979773905\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48585785679914245\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48360952379826705\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.48146678879993887\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.47941860088450916\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.477458273934696\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4755733860223982\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4737609195385525\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4720169450518708\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47034070531107686\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4687317289794039\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.46718059332216466\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4656834335595913\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.46423522154767016\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.46283577103436635\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4614812532517144\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.460170351361615\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.458898803161862\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.45766450053985896\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.45646495689316985\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4552972094109392\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6621471037190714\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6605408134557862\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6589782666349386\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6574581320169635\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6559733698943634\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6545214219260378\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6531004988212805\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6517068675439291\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6503445628548528\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6490068011463811\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6476930178875017\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6464019096429745\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6451318238913869\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6438813934202013\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6426494071862032\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6414346292983786\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6402363054662908\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6390500087165673\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6378781410131871\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6367200767154624\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5524958593027316\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5510714132719639\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5496895065097092\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5483491156618685\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5470454208082538\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5457769780057697\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5445418353552309\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5433357950694879\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.542157963192691\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5410058096799251\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5398787561507401\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5387720180719504\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5376868397121701\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5366228570005492\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5355772230535988\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5345474264492167\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5335340028006558\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.532536692859517\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5315545377732678\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5305880092864173\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5541951659979494\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5528598989099482\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5515531795556522\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5502732220469475\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5490181398037384\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5477875377242379\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.546581153229761\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5453961131183958\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5442302621567302\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5430835896225957\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5419547003072308\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5408425000627594\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5397457004577471\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5386625520505443\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5375945928847962\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5365403976562654\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5354993742699867\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5344717798992924\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5334590037848432\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5324557517587685\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.562433224879334\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5609057185978891\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5594180870383978\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5579673131220847\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.556550644915158\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5551671203054582\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5538158319018036\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5524938100000005\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5512006399086016\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5499334949964261\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5486925352692137\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5474761954908842\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.546281089601349\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5451080961513927\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5439556640873133\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5428223782181228\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5417084132920584\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5406136308733311\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.539535608009798\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5384745045921797\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6341899767084139\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6317574734819251\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6294228246181928\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6271815713326745\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6250295683432623\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6229584456409097\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6209600622928557\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6190288384804024\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6171628693916613\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6153555897813605\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6136022324786095\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.611899100639719\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6102420223705569\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6086298050201072\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6070577239541046\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6055221565592672\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6040223475436426\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6025557209528511\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6011202628838661\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5997139110635195\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7617986765876752\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7589511715962556\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7561847861874547\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7534993391043705\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.750889509316176\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7483517658821124\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7458861338142979\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7434908200851452\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7411554165693661\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7388730678343092\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7366352608042865\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7344535776298483\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.732320357061598\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7302302701500916\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7281720986627244\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7261543111471235\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7241823563506411\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7222461872144825\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7203409669409226\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.71846817674162\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6809427797499867\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6783290053784907\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6758009139342824\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6733476825201132\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6709649500876427\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6686554173462834\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6664118276152513\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6642304351184971\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6621073499781187\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.660038801996427\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6580214304980159\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6560529779954232\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.654132608438551\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.652254972493645\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6504180661033314\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.648622634429562\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6468675512691804\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6451484138001486\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.643463256746231\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6418118767758647\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6860682579376011\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6827187112384931\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6795231005549038\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6764686151074213\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6735399070693069\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6707143279432677\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6679847255128011\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6653546122623162\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6628144249501605\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6603538104911634\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6579599866219249\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6556374989673277\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6533816798577463\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.651186814267572\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6490499799589478\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6469537149079899\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6449013481962855\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6428944597250603\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6409266800231899\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6390007305579751\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5277149361273032\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5254855229007346\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5233558916770333\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.521319642735624\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.519362683175443\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5174736288344532\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5156538834184035\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5138948232292273\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5121917868436953\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5105410538545245\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5089376978026164\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5073753044343852\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5058528975272627\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5043688865720282\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5029220057224776\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5015128629431984\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5001370659587024\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.49879012528181416\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4974700653390928\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4961749628411656\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49608560249706013\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.491915903441077\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4880343231349805\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.48440147183641263\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4809897526882302\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4777810975055958\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.47475102531687474\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4718874306692984\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4691768445518193\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.46660543768288754\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4641659525301007\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4618454654068047\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4596358206266228\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4575260738664027\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4555049473177778\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4535651930119529\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.45169778326638155\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4499012030001345\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4481720244409393\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.44650337957425207\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.44673432001814917\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.44567032023591735\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.44462936663575625\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.44361379238624626\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4426199947410343\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.44164603551927556\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44068998839299967\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.43975012172747174\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4388268178088861\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4379198108038317\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.43702788270784676\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43615054438148115\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4352870455113869\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.43443597815248297\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.43359712905128284\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4327698204926223\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.43195401195171956\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.43114747147519406\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4303506708177345\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42956301131735963\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5256296075327727\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5239420745271843\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5222981508232778\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.520693207138796\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5191292606524995\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5176018646006683\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5161079524024738\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5146488131445519\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5132286322622405\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5118389952055169\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5104731199974382\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5091343568965456\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5078220113746237\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5065345755658421\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5052716308171044\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5040320414456053\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5028149557315751\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5016195867106903\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5004446864734757\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4992868143187015\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.608200343097528\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6052132043571339\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6023712895006966\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5996624429698474\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5970854852456827\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5946244155465957\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5922654218508505\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5900036871428128\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5878300283343688\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5857369167799021\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5837177518244165\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5817634904754373\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5798790601296995\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5780627646558946\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5763020933382057\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.574592781603666\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5729319744621535\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5713133485993396\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5697343986174256\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5681943415472642\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6950995694407521\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6890303339942796\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6832967071799048\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6778795415604872\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6727404114360656\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6678740581283943\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6632644701575918\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6588880008468353\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6547260106611397\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6507578468468673\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6469677809482492\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6433440832721049\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6398834832111675\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6365803949814423\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6334128657949717\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6303672223538412\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6274305208622053\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.624601060124166\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6218736030543077\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.619242630312589\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6843727729650049\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.681690855020294\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6791112307443877\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6766198295882703\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6742115521798088\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.671883534650507\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6696343972436121\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.667454646474\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6653352795917408\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6632719841458233\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6612629078226984\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6593012735174262\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.657390659426521\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6555271992369567\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6537061359640688\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6519241782226135\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6501792490888058\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6484705168688414\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6467952251961686\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6451496050521317\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6101362054878228\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6079131628303419\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6057847216383732\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6037322698897623\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6017527423546221\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5998378960903616\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5979831893455538\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5961845081387201\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5944365474851749\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.592734941082367\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5910755430528665\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.589455303374709\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5878718059502226\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5863285309138986\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5848250980597577\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5833548929019512\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.581913148344514\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5804981866251749\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5791088724324942\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5777418276090892\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6288278079715582\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6266229670280907\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6244719950263027\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6223734622847564\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.620325359125377\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6183234568111179\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.616367437585666\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6144524297402303\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6125762802728042\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6107385619656849\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6089370168241637\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6071695149096927\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6054342768299692\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6037308222680743\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6020579099495256\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6004138668191926\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5987947855110483\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5971992385718372\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5956273090585573\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5940787576261931\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5371486127501978\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5336316965703478\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5302953772500175\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5271254544681993\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5241057676779615\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5212332697310849\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.518501943903158\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5158997425856373\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5134133600928994\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5110222055579481\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5087425730257413\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5065603583870049\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5044602501062231\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.502432240829004\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5004832319454948\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4986051797282986\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.49679288725165693\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.49504153493669845\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.493351310138039\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.49171697362705674\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6129285230874791\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6104085790693786\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6080196752790168\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6057462847711239\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6035772056176532\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6015051479938776\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5995207888386147\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5976135473766216\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5957788119991541\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5940107757773972\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5923033544146292\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5906493399580683\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5890441965034121\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5874840797217334\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5859636529518555\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5844835183228022\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.583041286509052\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5816375528092186\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5802643099087816\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5789203579644133\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7762311690381133\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7729562844609874\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7698153397165495\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7667926807842373\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7638806943055327\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7610661813945521\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7583568142333765\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7557332526192885\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7531893063301852\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7507190067998653\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7483175470599881\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7459824858666056\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7437169147412268\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.7415055259489429\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7393421176113996\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.7372243604613453\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.7351562516566952\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.7331340368394742\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.7311553829553068\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.7292177089973899\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7362443338251969\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.7320439956646723\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.728089662592077\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7243692743354547\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.7208549128676078\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.7175341542672928\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7143821445566545\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7113904782555267\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.7085359465632419\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7058075723147244\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7031958862086949\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.7006907973322001\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6982803117946477\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6959563118855914\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6937116866081648\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6915400822619353\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6894363866761577\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6873932415716097\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6854049426926068\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6834656102005976\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7020662839287857\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6985164079992954\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6951139441214627\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6918553184233567\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6887176160611316\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6856923055821638\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6827718628663326\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6799461424134415\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6772143080115487\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6745728571111329\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6720116850978968\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6695280793335692\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6671172772262879\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6647704183024864\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6624870744685718\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6602627638772075\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6580900855263256\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6559623298423307\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6538836240270907\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.651851092246726\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4702379349689228\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4687466701077697\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.46729597340016393\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.46588932944360184\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4645236142135214\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.46319615821966953\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.461904024059069\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4606450278705372\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.45941755225647\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4582198142844656\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.45705019951821935\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4559080585021371\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4547902036816799\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.45369672889752133\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.45262421664228125\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4515721454156836\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.45054363269869574\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4495336984936884\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.44854207574209737\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4475655273981468\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.43312062970230747\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4307459357853591\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.42848619252835696\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.426330823816378\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.42427000202776133\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4222992669794893\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4204055245356275\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.41855920010722125\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.41678613814442167\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4150827908733054\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.41344479170170256\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4118613823426369\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4103279231489696\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4088425789327056\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40740284339733396\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4060070194637908\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4046503491820457\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4033305571061652\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.40204477016211393\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4007911670704007\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3947557847737193\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.39305583969934477\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39141883955725815\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3898449928436296\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.38832899445779756\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3868667946236727\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.385454700615816\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3840901459458659\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38277239497360027\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38149784635457223\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.380261561195094\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.37906075126715133\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3778961976161437\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3767660604860571\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.37566882825236303\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37460114187047655\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3735614012004449\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3725470316619035\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3715567966115171\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3705890894602714\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.51518244383441\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5121953774541123\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5093588230013975\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5066558310163717\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5040801714718205\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5016241825823022\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4992779755461033\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4970349344124054\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4948903286293813\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4928439163963999\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.49088058752116837\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.48899699132290403\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.48718532332024167\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.48543868860437356\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4837546893006005\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.48212975595288404\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4805610017816134\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4790423813738569\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.47757010160519786\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4761406271220743\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5090499204906525\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5073352696772437\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5056695295925391\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5040505757938928\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5024762479613574\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5009398966549206\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.499444334456341\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.49798571094480126\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4965610711361348\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4951681388318118\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.49380568353544846\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4924727086105999\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.491167859902545\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4898889792254323\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.48863542446862485\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4874065025070531\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4861989935008621\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.48500661815299456\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.48383277599594876\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.48267630846804277\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5313608402645852\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5274056131910124\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5236553773778869\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5200967359647248\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5167106204670455\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5134769632214844\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5103985872745398\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5074606912177411\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5046540783887703\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5019687584994278\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4993991254196076\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.49692823800147584\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.494548421586225\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4922544920067342\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.49004521757874625\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4879178868787323\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4858656446871691\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4838843538457784\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.48196939163550745\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.48011689455883977\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.45836233042219254\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4567730440454939\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4552328723076717\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45373788638050006\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.452285567221362\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4508795658697906\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44951169090960486\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4481789932072218\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4468791260015843\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44561023293871305\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.44437080277264424\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4431599326624893\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.44197612629264244\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4408185016377577\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4396863296344468\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.43857742817260864\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.43748920369105054\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4364226643616136\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.43537519808192765\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.43434549009858026\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.43393075538011316\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.43220466051904904\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4305450691414009\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.42894912025856813\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.42740867789643977\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.42592432745620745\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4244907751189604\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4231085883558814\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4217736426916673\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.420479764168599\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4192245426717119\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4180054401387049\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4168207871467518\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.41566719709061417\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4145433709838529\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.41344913103846137\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.41238311077940293\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41134813525625175\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4103376295616916\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.40935175400174284\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48969186750995536\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4881361090770689\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.48661649560910974\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4851330218062684\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48368182300230644\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4822601999514401\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4808666529200822\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.47949816627810915\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47815424045272703\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.47683495120200026\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.475538562904097\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.47426519895812813\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.47301275451384983\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.47177928381558343\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.47056447129526835\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.46936851087685183\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4681910750602547\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.46703012286041645\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4658844377985003\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.464754695646197\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6098644751554868\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6064674615359276\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6032073654506375\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6000743009508391\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5970537476678938\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5941470645907505\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5913448931899127\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5886476655482058\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.586042712184043\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5835159853671712\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5810756950705401\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5787161391032487\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5764374130077647\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5742317347932531\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5720890224406279\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5700066301617646\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.567980604150865\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5660090691553327\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5640881097115502\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5622136426961719\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4821689397750201\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.47942210584933453\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4767936605750007\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4742748816183229\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47185551510320123\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4695308272204234\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4672946734996798\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.46514274873203554\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4630672919573687\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.46106847277196694\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.45913621924471015\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4572659162321531\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45545418033411533\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4536975753850624\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4519937276376875\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4503379922014808\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4487272132428149\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.44715889398335984\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4456283236635574\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4441341065957154\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.449270346756619\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4468651996423264\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4445870625561071\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4424196919335608\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44035589046835466\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.43838639477321617\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4365042036531098\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.43470423143149267\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4329794407575194\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4313210827448268\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.42972458536501634\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.42818593356708823\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4267021572258683\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.42527171646657563\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4238873461031252\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4225453663591613\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4212420083932856\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4199773733601419\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41874762817471156\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.417548906934035\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5059009097428542\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5034416273292837\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5010941421546\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4988538767229629\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.49671683753640056\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4946688664453534\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.49270186043589564\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.490811849026385\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.48899416637903603\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4872420690448456\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.48554451386349257\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.48390174923653806\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.48231207104990276\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4807732666358882\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4792821056782636\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4778374671578096\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4764345672134332\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.475070151454495\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.47374100997303015\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.47244475638659056\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3316348633822449\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3297632635333416\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3279911578581537\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3263166741336089\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3247281314120766\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.32321833306997233\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.32178340854399773\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32041730726714635\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.31911742383635555\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3178771152706856\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3166913290457926\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31555611832766883\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3144673582688865\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31342132204185785\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3124156858184908\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31144901744125225\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3105162987919958\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30961833796963323\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30875016580162457\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3079097369952169\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3491369729460676\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3484477920048026\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3477664692662491\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.34709257568610963\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.34642576884053367\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.34576600404322555\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.345113421418529\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34446865175184743\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.34383228175349445\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34320276649775777\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3425790595270116\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3419606154541237\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34134844732983227\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3407440317947592\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3401448210355176\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33955043438655474\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3389595796073274\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3383728610008023\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3377904444527787\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3372120765132085\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49939782100743135\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4959029813921246\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4926178956189432\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4895203826420642\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48660161273729796\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.48384477248552643\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.48123787349011327\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.47877011807860753\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4764310526863092\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4742095498102118\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4720963587050131\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4700809856738162\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.46815791880055124\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4663155242405155\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46455110602637706\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.46285654468752147\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4612257309105391\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4596525120678043\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4581331505484942\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.456664992290957\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6469127364977811\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6415872950203909\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6365965237889335\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6319172435332565\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6275262294814838\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6234055355194763\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.619535831140191\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6158928990599616\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6124568063094281\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6092120998829329\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6061448226472972\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6032427464375942\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6004870381810116\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5978648464618416\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5953656078857494\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5929829042658916\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5906986588362151\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5885137715275287\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5864174825865658\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5843992335765174\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5685693169812522\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5663139667828341\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5641414354335605\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5620487420018643\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5600319477236313\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5580969020220113\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5562225630683919\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5544059842503396\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5526442046142829\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.550933730759869\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5492709193441606\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.547651406988346\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5460739553154645\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5445401275857121\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5430466258593338\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5415880583769929\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.540161603994167\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5387684469036893\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5374050883922932\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5360707423065697\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5060860307165573\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5038941581912695\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5017960533542937\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4997839861818042\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4978552018439406\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4960026273463163\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4942202173231946\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.49250223681013716\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4908457409443614\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.48924735799974084\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4877029328273085\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.48620965426076446\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4847634277061981\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4833623590373227\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4820047299731139\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.48068353734896657\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.47939791004820387\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4781449278195773\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4769238219044092\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.47573260876865453\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.35876884308027335\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35761994137440767\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3565011562752982\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.35540887116697917\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.35434214007165454\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3533002641061106\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3522813080021531\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.35128569914606766\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3503103404434201\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34935411985507026\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3484161005714788\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.34749536925268365\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3465924600668844\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3457056345572973\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34483381907938904\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.343975812326648\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3431288746323826\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3422939108509807\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34147012355561807\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34065794480575684\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.42268099643225404\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.421031191357049\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4194286806608548\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4178673711050401\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.416347518084842\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4148680101940179\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41342973288021995\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4120269617190181\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4106581136907351\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4093224970641238\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4080169076036319\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4067411244405563\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4054920219836108\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4042679851701999\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40306738855895874\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4018900420361357\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4007353189833781\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3996007197715258\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3984845494408564\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39738735184068696\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5212976361249305\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5171866006294317\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5132935775872416\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5096109493321551\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5061281232641655\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5028222463568497\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4996852641649277\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4967039402030876\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.49386992343731306\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4911709901060164\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4885972111031264\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4861376111510124\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4837618974447975\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.48148827790763193\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4793110559368359\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4772232696506238\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.47521833254667045\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4732884404569727\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4714321777869217\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.46964666516505654\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48805464623805145\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48592340266773654\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.48386718181888916\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.48188264579998097\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47996172056364117\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4780880895437022\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.47628075614982934\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4745325963562217\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4728383269610076\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.47119609228558623\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4696025210354694\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4680528980429395\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4665466431040784\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.465079094113922\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4636504002269086\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4622600234378831\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4609042828506776\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4595792288128766\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.458286332238961\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45702583371911376\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5881026976960539\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.584737933456019\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5815227589144205\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5784523138855142\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5755150585690313\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5727020507556257\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5699924811644185\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5673762743613392\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5648563114618153\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5624302328861055\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5600905981292514\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.557837139279785\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5556706898518506\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5535796760802678\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5515626915878032\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5496062716142905\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5477003020951381\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5458488378122602\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5440467421038941\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5422894646357099\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48940881465907493\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4860465884552886\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.48285805825979766\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.47982785437950126\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47694473395289927\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.47419926331529916\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4715840859640678\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.46909108265555927\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4667111189343771\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4644381467099813\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.462269728778131\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4601929701009615\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45820421921114496\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.456301872044534\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4544843512797254\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.45273662573939755\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4510572188014289\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.449439660018252\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.447881679135531\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4463788802644677\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.394694772317876\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3937181791595802\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39275690512014544\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3918122172940518\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39088252740588564\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3899664063029912\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3890631667990091\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38817318817196494\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.387296424705863\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3864340077899587\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38558322627358593\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3847431082175302\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3839136394683035\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.383094454088751\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.38228457478962885\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3814837055942877\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3806916153867461\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37990759700538845\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3791318467390886\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.37836352320515065\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4461912115195943\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.44359782653768953\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.44112292534809155\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4387577361418752\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4364964621774591\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.43433110909852995\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4322563024164251\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4302703665612102\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.42836524226434547\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.42653058000043853\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4247632449686979\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.42305794235245925\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.42141001709170944\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4198161319323965\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.41827164291492747\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4167759062388107\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4153282363164143\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41392408129459624\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4125588503281562\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.41122881741787787\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4443859274328511\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4402885000261215\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43644292028754\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.43282563268871527\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.42942056397201445\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4262062582924578\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42317359748518113\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4203039013846077\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4175749469022874\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4149776585479829\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4125013319141909\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4101324534405872\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.40786314599463913\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.40568635735210123\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40359286767193314\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.40157669218634817\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3996316416948543\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39775313236805765\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39593397675166025\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39416939163704845\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5430277608139642\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5386941077222531\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5347007228381542\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5310125813173192\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5275875983964158\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5243906468686581\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5213948155823012\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5185712422696562\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5158991857226083\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5133597783420466\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5109449905105142\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5086429501880806\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5064472085972004\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5043416391562126\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5023179460524707\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5003736972422919\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.49850286427194185\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4966993680208277\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.49495234429962787\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.49325122487847217\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.41524749733128175\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4137293536147829\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4122523021697355\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.41081258018224304\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.40941057050738117\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4080442785330342\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40671156400733965\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4054110134420195\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40414113245958283\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40289869297564496\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.40168367413478634\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40049499213626283\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3993316325940172\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39819340039407947\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39707719149333076\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.39598340926444175\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3949094023590974\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39385619292609003\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39282225506584045\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39180662690119034\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.24015425581145494\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.239194588061375\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23826487850622957\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23736357028195298\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.23648842428699546\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23563608275914705\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.23480765091113703\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2340005143124345\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.23321409985864783\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.23244700688078931\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2316982044625333\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2309653504607622\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.23024839827821933\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22954660996601334\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22885912749414955\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2281835545156615\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.22752134840807964\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.22687178646007716\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.22623166948092416\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.22560295756232246\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3774458812006077\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37449562181496265\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37170750863054824\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36906596293412036\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3665592920979772\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36417708946090876\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36190853717423443\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.35975611816734054\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35770411772105937\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3557444965546478\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3538724429041051\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3520815888590778\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35036517405676176\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3487182559716586\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3471353764763222\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34560995468319256\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3441401472687213\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34272191198412794\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3413539387891165\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3400306348311556\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5414163571957736\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5380507609142294\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5348459443642091\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5317856248170081\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5288606378609584\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5260645603072617\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5233837085685703\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5208101970029968\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5183339984025218\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5159592679371454\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5136642365092752\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5114438561840986\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5092957820564601\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5072106947711282\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5051907100711975\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5032257912649101\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5013214638931422\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4994685646872931\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.49766133933324286\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.49589543139979186\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5162737309431535\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5132149926874154\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5103089457519538\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5075441383233872\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5049091479458976\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5023955174236654\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.49999936950776125\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4977112948060176\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4955208792956707\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.49341914311175766\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4914043386030581\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4894749961765934\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4876207594510278\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.48583446567100247\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4841269843147459\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4824822566515678\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4808961491033724\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.47936037599069004\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.47787170742136154\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.47642782584755894\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.40047634329032383\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.39885982167715617\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.397295047775732\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3957771056376611\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39430359374845814\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3928715645369517\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.39147749886581173\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.39012115965446786\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38879948633836414\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38751159741188984\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3862534204269867\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3850241718430954\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3838230496938302\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3826491445285739\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.38149968314255833\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38036886659372415\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3792604647212033\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37817388816049025\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3771079208717382\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.37606142409349097\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.66762696742608\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6630321246182673\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6586379513384504\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6544298087500268\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6503986785665874\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6465304296142658\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6428190312109434\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6392451375402506\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6358034627174081\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6324832910807606\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6292836771532737\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6261913872187408\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6231956387777877\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6202916929982205\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6174873517305492\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.614766826991372\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6121230060844072\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6095525500454716\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6070562783200297\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6046270626618413\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6939213513351659\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6892741462332983\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6848207574000823\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.68054123208421\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6764222211152257\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6724516446829818\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6686262277824793\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6649470315472162\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.661389938816203\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6579502971186971\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6546201825234514\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6513920239085772\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6482592602200508\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6452192343474004\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6422713287665497\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6394026850453689\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6366110036377538\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6338946788438466\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6312468200828212\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6286639245336278\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4271764051904151\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.42353981490858966\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4201160806425967\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.41688555138230277\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4138327563429949\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.410945729232042\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40821214184195154\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4056168037362634\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40314106251139403\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4007645350120239\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.39850387116443764\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39635430777732317\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3943083398226076\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3923525310443959\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3904717851047575\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38867487359590513\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.38695199045356005\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3853008305963872\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3837181195921672\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3821968639499956\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3868245492801703\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3843599009663509\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38204354012351993\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3798641944175249\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3778102120464164\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3758713470288464\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3740425605438552\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37231082724860687\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37066464887054723\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3691005707368805\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36761088801637676\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3661911353799477\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36483525039609527\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3635369917732977\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3622911606431143\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3610921360110254\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35993762658030326\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35882433174438344\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3577491792316514\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3567083396939918\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.33247332558704723\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3310059737603601\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.32959211607358985\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3282283853534315\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32691025717357614\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.32563429860336357\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.324397281264079\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3231963016053395\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32202969487097277\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3208981353830134\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.31979517464561347\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31871907596005367\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31766797417665626\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31664209621777745\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31563864462923685\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3146553574968364\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.313692213792399\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3127484194359752\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3118223402517023\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31091354258116266\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4781082485156064\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4751885168850181\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4724141173588887\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4697765566380293\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.46726644563302405\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.46487161622661144\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4625824275998033\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.46039092449339836\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.45828867618335256\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.45627113597083213\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.45433038839331663\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.452458310390722\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45065016369978095\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4488993823736321\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.44720443291075074\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.445562932684436\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4439695169242599\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4424206938103056\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.44091437795133465\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.43944613498758733\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3538720907571043\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3518526905015406\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.34991421352201146\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3480534929367659\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3462666006847256\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.34454383276207756\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.34287859577453983\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34126950664015754\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3397149971892018\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3382105616367074\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.336752573294522\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.33534096582758943\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3339739095494682\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.332645246373236\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3313543272987484\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33010621706315835\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.32889037433528623\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.327705340084326\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32654939118368426\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3254209129094393\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3526459780730377\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35060474594244917\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3486766233821056\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3468489801020245\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.34511506640875034\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.34346849093682796\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3419050458314645\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3404144523115856\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.33899486397442063\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.33763488653145873\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.33632965530587466\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3350763953443634\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3338725284892454\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.33271243293779096\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33159323066803226\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3305130457814938\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.32946815801067997\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3284555169332588\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32747284260964504\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.32651962149585156\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4110322346929206\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4097344016085917\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4084744355558293\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4072511935460811\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.40606162112436595\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4049049172286418\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40378058382241167\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4026856297334963\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4016173194016004\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4005737711059723\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3995544839439512\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3985577344803451\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.397582312832491\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39662813110143813\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3956944387066006\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3947784239970359\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3938794052947906\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3929953269623736\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39212615093201103\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3912705370322053\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4371193861366124\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.43540159725935945\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43372876067043653\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4320996499627266\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4305118542297426\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4289641344728834\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42745428314098216\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4259785426771691\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.424536773191431\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.42312691171766204\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4217489922435036\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4204033877702371\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4190863808171262\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.41779813209934313\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4165363292833132\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.41530004215517086\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4140886221542238\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4129015234859502\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41173718301609225\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4105970434971447\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5097724247523813\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5073858304088248\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5051009926030642\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5029068198226887\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5007979909118465\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4987749628525609\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4968210359554036\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4949335983013956\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.493113506324841\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.49135667815897616\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.48965735558247103\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.48801124509273686\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.48642066487219815\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4848796231439593\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.48338558058602554\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.48192969946384323\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.48051409367439674\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.47913609726229334\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4777937730445656\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4764861071107641\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5071134038927074\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5040972236087876\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5012116662817526\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.49844295615967527\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4957840986636316\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4932289442860777\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4907689866885833\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.48839264993412873\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4860916860879122\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4838691834643989\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.481720883662508\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4796369874831905\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4776220330069105\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4756674757658238\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4737656540699402\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.47191395751170395\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.47010911838550695\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4683492616353522\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.46663537727572313\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4649610765458896\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.46110071288007004\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.45967860278234723\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4583032120821942\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4569693728723314\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45567353634123203\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.45441350853963636\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45318760818602116\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.451991998587054\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.45082557969723835\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4496868819353607\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.44857527431618865\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4474879062162067\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4464217943336817\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4453762274348192\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.44435103202116677\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.44334520709237624\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4423572761309754\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.441386366975561\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.44043056727118784\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4394885331586461\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34795854185735275\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3449020737798797\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3420334130211483\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33933053779036304\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3367824364114449\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33437556414772757\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3320960805935327\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3299406608044563\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3278998391928981\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3259650605994706\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3241321405696691\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3223913747831958\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.32074036078171586\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31917370185304106\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3176799352623091\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3162525530692162\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3148859807775909\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3135778187083771\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3123236675687481\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3111193481387518\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5101541721136019\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5084928184397568\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5068823715740995\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5053224032525014\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5038098626129132\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5023514055240461\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5009315617697441\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.49954778062807126\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4981963785639703\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.49687659858286604\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.49558958562049643\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.49433041113222254\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.49309543003006207\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4918830726291603\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4906922284500331\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4895204764853943\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4883719040147905\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4872416182331141\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4861302976600904\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.48503504031903\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3780530919102773\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37677966165726184\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3755482328996823\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37435781066719576\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37320413262672436\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37208214755473884\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3709865264909783\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36992076673138197\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3688830339946903\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3678711063864535\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.366882949304544\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36591672197826797\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36497574836654123\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3640571699593679\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3631567562547263\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3622734256209084\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3614051958108796\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.36055342619209313\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.359718384297217\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35889663409235545\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48277085046479173\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4769716336321919\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.47158372026334194\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4665835015078378\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.46192571728054255\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4575814232635813\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45352964821869446\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4497099589727249\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.446126374191382\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44276159086598915\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.43959609354884194\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43660797149902497\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4337795196739117\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4310955077694852\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.428545345993793\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4261132552646807\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4237872338990307\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.42156621335804184\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41944509594531565\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.41741213231293556\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.535901610755254\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5331251735716164\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5304976977128173\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.528001785533889\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5256299492675435\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.523371949266756\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5212180510639381\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5191542399531893\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5171721296921281\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5152641839380028\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5134223463400713\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5116391994771905\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5099095855414922\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5082303819056213\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5065957260217044\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5050026716571818\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.503452946241619\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5019424989758343\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5004650377247559\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4990160724676327\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5950102887017166\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5909686730767768\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5871764845271208\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5835980440602394\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5802159883822088\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5770128634696766\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5739717364547783\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.571070511178668\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5682985372692975\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5656481437545966\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5631146420073943\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5606786956026693\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5583292388420646\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5560594378912544\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5538632397725836\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.551733728169718\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.549671402257849\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5476646776394171\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5457083297832797\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5437997699942171\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4461999914627714\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.44402366727417997\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4419465585935763\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.43996253430916926\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.43806638041607093\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.43625058510107145\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4345128049843666\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4328445314484855\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4312408168184007\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.42969685366307303\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.42820792644020533\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.42677652801692467\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.42539279188664547\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4240539913094251\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4227574311758985\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4215007418150964\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42028141600695174\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41909742125255905\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41794557398191573\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4168236561765201\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.368839031279642\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3671174082268832\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3654788191443143\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36391745105324314\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3624273116630994\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36100053681580124\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.359637228221132\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3583367466574689\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3570891081486957\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3558920567030113\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35474060286114\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35363118973679997\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35256113564702585\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3515281073924647\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35052975793532426\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3495645223201881\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34863202653663744\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34772659866545963\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34684627445942723\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34598933711377555\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.45081715794078936\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.448668185029791\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4465761966288857\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4445397589046366\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44255751341342087\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.44062677808069406\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4387461273932679\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.43691379033695554\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.43513125136163344\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.43339129549302063\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4316915454480414\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43002704720887414\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4283986256256951\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.42680504958404186\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4252447020292463\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4237166773197206\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4222195108851341\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4207537634071131\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41931693392041364\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4179068785312896\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49103725451042757\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48810582889831944\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.485327042161725\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4826875528045176\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4801828616026067\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4778000361521162\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4755259463507149\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4733494103717689\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47125789785110894\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.46925241826345815\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.46732557998583957\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.46547138613634664\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.46368669015468944\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.46196449700897974\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46029546510334973\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.458680787951787\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4571143466105751\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.45559540211960503\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4541185996239476\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45268240164229945\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.26234805082695395\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.26023932618646833\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.25825272295366175\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2563803328441719\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2546108459719879\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.25293548483203737\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.25134687506586784\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24984136494061357\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.24841292977378848\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.24705282249961014\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24575650514609615\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24451890983992206\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24333491877672134\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24219933430818127\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24110993863083316\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24006410197381023\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.23905530952552984\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23808179138592078\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23714294006290737\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.23623650848392824\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37189147580299736\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37014814072637414\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3684812369191718\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3668812521855503\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.36534394632246503\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3638627530203062\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3624361742267638\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3610594837640702\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3597355790914052\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3584584093700207\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35722431211241407\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3560324892370013\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3548786044854845\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35376121750444384\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35267917534753146\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3516294767161974\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3506097157629505\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34962060067630885\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34865782309588\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3477197309447596\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.32477265446403825\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3228408584906345\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.32099122725053797\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3192190051377834\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31751931717457393\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3158858155140649\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3143160257108803\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3128065597267752\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.31135395692164836\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3099556808653433\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.30860819187591493\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.30730660944466587\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30605027940099516\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3048351490153459\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3036583708675631\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30251855319296017\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.30141340863751465\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3003410109567141\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2992993333125016\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2982857368266201\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4437787252712069\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.44190897351878805\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.440104262445499\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4383543048686229\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.43665750138951137\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4350123889248889\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4334171570241946\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4318681220240076\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4303606715432271\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4288944847650498\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.427468069780563\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.42608013713831183\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4247266615935543\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4234089783061414\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.42212419898658726\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4208729341310602\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.41965147842169537\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4184554950695867\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4172868438284536\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4161441960501146\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.39638592992521615\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.39521986181453805\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39407348401135867\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3929462189077977\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.391838798673636\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3907483029215593\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38967458177624015\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38861655047228183\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3875730545828333\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38654594117496166\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38553576668631184\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.38454014525869407\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3835577704011908\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.38258806999428685\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3816307232892838\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38068612500034327\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3797522538969603\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37882912366482235\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3779162679671075\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3770133124471898\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3337197380647421\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3324514423773319\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33122856506445997\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33004528852132176\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32889954268444177\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3277878369420081\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3267080480237623\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32565729567126916\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32463287522200934\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3236364879868462\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3226654716288975\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3217184715692528\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3207927512470581\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31988619088180503\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31899844792560067\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3181287040804949\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31727586608797825\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.31643853976271163\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.31561604738195903\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31480767100279444\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3241756156848312\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32314047020619874\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.32213184558853664\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32114870721750866\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3201893495118382\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31925265986877394\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3183380386547824\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3174440078856945\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3165690447077638\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3157125029414366\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.314872970735224\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3140498961544799\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3132427954642823\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31245029870225893\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3116726438114884\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3109088558219466\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3101577353991345\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3094194972603292\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30869308735403456\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30797771417778347\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4162792461043753\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.41445181751751975\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.41269660023397925\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.41101258628507986\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4093996812280706\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.40784845820379756\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4063542762908666\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.40491145703645987\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4035164729403381\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40216886756016057\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4008677755338445\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3996044527374868\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39837955408254255\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3971950760463733\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3960463282056541\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3949301184037627\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3938528330791473\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39280237509678867\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3917774144198556\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39077729076051027\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6056467279768306\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6031438058376271\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6007268036694534\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5983886538469054\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5961194231449602\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5939161434251616\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5917751932972135\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5896940149445984\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5876661990162021\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5856876061512521\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5837532960146996\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5818608843703528\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.580007175421587\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5781909013546134\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5764147220409884\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.574674296205935\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.572964368498462\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.571280592247658\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5696254131968955\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5679979255682882\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.48397323688252475\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48239917786306646\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4808497532387895\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.47932129452199096\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47781729521419786\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4763341534474554\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4748730740398725\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4734350748697903\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4720183995098792\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.47062144096214037\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.46924357160766506\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4678828996426918\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4665409903223518\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4652156277525031\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46390702078895446\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.462615375684561\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4613409528280074\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4600802681391371\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.45883575157122697\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45760613212692197\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6435015503105712\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6383384775835983\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6334423243247325\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6288027677891295\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6244157858863663\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6202411917184115\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6162723701797101\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.612496457696668\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6089029841858238\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6054791078609563\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6022168571805655\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5991017723632817\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5961220060726742\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5932662241884762\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5905362294381085\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5879181903069453\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5854018226719333\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5829834387413073\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5806612741060506\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5784318382457548\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.41138472503911994\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4096475567040074\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.40799295301727245\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4064128597816883\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.40490096976280177\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4034541966808832\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40206710011251706\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4007355962037938\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3994567950916823\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.39822254410149016\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.397029881356406\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3958775211585567\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39476155600795015\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39367850245716274\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3926259505551528\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3916012509620733\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.39060274529878636\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.38962896745846104\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.38867704674564296\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.38774508314418443\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3884472491141016\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3861409692287563\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3839401608798346\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3818316912313136\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37982133284532504\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37789977308915434\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3760594578722014\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3742965548812408\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37260490909490174\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3709781607814469\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36941212427704606\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36790348504051634\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36644761452685015\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36503991312349426\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.36367611120853927\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.362353956215659\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3610699247090087\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3598235728728666\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3586114465344112\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.357429402702783\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.36072750129399533\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35886690689486234\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3571336589024855\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3555068086813792\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3539757510444118\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3525297135260629\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3511543543716758\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34984376099198405\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.34858828897976535\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3473815518948538\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.34621872497959694\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.34509545657482477\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34400615090787245\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34294914704232504\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3419207813265091\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34091818815629127\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.33994027653849646\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.338979357614082\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3380355175832436\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3371084774377806\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5375774892725735\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5329715933085037\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5285681987934782\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5243634959824147\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5203430833568035\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5165006759160011\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.512825995901153\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5093080699240357\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5059402534116593\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5027128729355905\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4996160974651924\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.49663748178860456\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4937701221975455\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4910116171075979\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4883499768049874\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4857809106831718\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4832999166990268\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.48090382901246\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4785890045753943\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4763519500861837\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34284936670449623\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.340571480411879\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3384384128403186\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33644066148597795\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33456203900872616\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33279453196976094\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3311217494509753\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3295349641930675\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32802834252942853\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3265957443594018\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.325230762296662\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.32392612516952674\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3226760963609758\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.321479690961602\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3203284964715316\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3192182916088009\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.318144137870916\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3171044290589028\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3160945217030416\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3151140597124201\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4523638257237577\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.45031537378610004\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.44832244375020014\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.44638450221689385\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44449676467700117\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4426571014172003\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44086251646220853\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.43911118790240244\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.43740370620101177\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.43573986932204284\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4341118555114385\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43251852765614474\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4309587803014946\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.429431637486304\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4279361490824217\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.42646883926690005\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42502964925065156\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4236162412562976\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4222289245678681\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42086476912871634\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.35581490311758773\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35463195252798096\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.35347875099775933\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3523531615011271\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.35125327137876156\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.35017672177185005\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3491224792221639\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3480895570784972\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3470785803562463\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3460869348219344\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3451137858654506\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3441588654039691\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34322093081444927\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3422984623690196\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34139281703541347\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3405022558280511\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.33962003598113544\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.33875093462752315\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3378945025620558\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33705071205358034\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38246912898115387\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3805037982962271\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3786076660680331\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37677859407157466\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3750107826024822\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37330001395909773\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37164530878815133\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37004481738197725\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.368491813223326\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3669857027575534\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36552437277028565\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36410572522977913\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3627299576160763\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36139094499684454\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.36008573392607923\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3588123717380984\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3575686498748002\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3563542470828849\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3551684939385436\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35400848577805843\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.435652240804594\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.43349163774981214\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43143058941776635\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.42945772357595524\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.42756565659997947\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.42574970857945676\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42400746778758414\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.42233026892575304\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4207128049425945\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.41915391691829895\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4176508041766635\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4161973085883064\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4147906943696368\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4134301184510367\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.412112597185233\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.41083283567163165\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.40958935696833565\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.40838200044820966\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4072080843358533\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4060626716020168\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.29244339678292736\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2905750039301265\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.28880972271837524\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28713732190341623\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28554950694080944\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.28403610939317114\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28259041995651635\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2812062219829554\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.27988183230125807\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.27861210824818383\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.27739035071143475\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.27621293683649817\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.27507700690712733\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.27397917589347787\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2729186728571873\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2718919800841799\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2708949041606126\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2699260047559822\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.268982848502623\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2680634793892956\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2912524974306291\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2904152211338713\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.28959172353361073\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2887802066957642\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2879805306354994\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2871923042354959\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2864152894068566\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28564841832773613\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.28489198979375974\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2841450983005918\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2834075913338222\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2826783872087945\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.28195843191075465\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28124585088904325\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.28053901415933913\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27984066366252514\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.27915023787736454\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2784673493112969\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2777929747046572\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.27712613245808787\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3901909610602682\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3872311768891944\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3843985913001303\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.38168449067326354\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37908233323200574\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3765857329375432\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37418880317765646\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37188524084629443\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36967209186381406\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.36754287313621653\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36549295869922666\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36351815529269244\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3616138300039118\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35977524065781896\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35799597253679416\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3562751118381421\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3546102929091317\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3529991618737446\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.35143764949892353\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34992316920928795\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4754794634135084\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.47252846335421084\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4697295546311638\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.46706910039105726\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.46453421914023685\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4621110034633405\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45977278552813494\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.45753944412858133\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4554027325786647\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.45335929537496067\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.45140259096048\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4495155001749641\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.44770251165177144\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4459565214226305\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4442730221809047\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4426490233578989\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.44108258643719966\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4395690265914268\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4381035114917796\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.436682357770937\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37637130377218353\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37487858970522286\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3734371145019744\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37204174489219466\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37069097247060645\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36938320445522954\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3681140598383013\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36688148393114034\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36568357522839445\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3645184549039713\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36338405076267744\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36227777076966816\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3611970858911106\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3601416433922129\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3591109806030821\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3581023797338674\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.357115468987407\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35614840597751146\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3552014595789844\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3542728611609598\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.579367883309724\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5773649193688962\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.57540895937039\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5734966397494129\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5716255968361929\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5697939686880332\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5680020570428652\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5662452680532647\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5645259722144533\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5628505756326727\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5612053128931711\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5595865659400865\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5579970276561829\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5564341937295503\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5548957890172304\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5533819030919561\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5518946985118376\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5504285047408704\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5489825452291525\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5475595167586934\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3852863506417413\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3831033658138306\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38102714624359013\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37904617592854917\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3771499366096755\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37532813395242526\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3735756973170974\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37189059644865285\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3702665152335196\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.36869732758795737\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.367177933653649\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3657037303467563\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36427182997797797\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36287929154857723\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3615233684381247\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36020125071551534\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35891361298305124\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35765708296433213\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.35642849681242794\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35522505473790034\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3431167822471865\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3404549601804352\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3379171343562908\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33550363725312915\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33319937818968237\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3309995927673026\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.32890088219889374\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3268961604077463\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32497922722703887\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32314238093611325\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3213822458198996\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31969015386366173\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31806091014500026\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31649107499030604\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3149759424457489\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31351395134677673\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3121019095453772\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.31073655014628143\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3094168422970103\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3081386384847035\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.35523541200523645\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35362447515115913\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.35209837247629056\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3506493861349932\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3492705022947099\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.34795489759500214\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3466992080093879\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3454981002941825\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3443473130848499\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34324200370665076\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.34218016772688137\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3411580808612349\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34017292963383633\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3392211352247813\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33830065693128925\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3374095323113204\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3365449604957927\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3357061416617766\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3348914671955305\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33409892143310393\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6336926585955285\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6282487741898123\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6231522407151865\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6183814033549188\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6139083754142194\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.609707835053512\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.605744551286272\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6020062014763905\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.598476379161667\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5951339198386308\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5919627139379353\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5889494043623693\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5860778621307288\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5833306917329056\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5806950391609311\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5781654533750521\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5757319098413213\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5733890638985508\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5711332154884501\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5689605595095178\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4106976857667949\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4094752424191594\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4082782108242336\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4071063220307899\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.40595687178433293\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4048306664265431\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4037255316612557\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4026383469090996\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4015698142166565\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4005180325788086\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3994822570796637\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3984627104038085\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3974574468885972\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39646556221375506\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.395486845854796\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3945207748816305\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.39356662087750555\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39262421902488087\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39169281076603807\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39077234944976175\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38521766786271366\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38342869128093676\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3816948863579587\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3800139184812673\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37838378472074174\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37680274229095934\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3752682321435135\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37377618954234193\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.372323380567805\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.37090749218556723\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36952828439360497\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3681846009709672\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36687336146353916\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36559185696678687\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.364339239259761\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36311468921432244\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.36191618188480124\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3607422207090592\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3595929897845034\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3584668599716275\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3967115526047068\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3898775811396721\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38355744482572973\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37769396975405245\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3722654303392531\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36723239319942136\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36256060869533646\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3582221417047464\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35417734868671313\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3503980149545585\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.346864837925244\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3435495050217416\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3404330365518578\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3375010435749363\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33474270070988754\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3321419521820682\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.329687766510373\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3273627623664786\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32515180620641093\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3230430799527362\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4228544551701708\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.42053861257264036\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4183090564288184\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4161660495180475\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41410994686107383\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41212596457722483\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41021210118290796\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4083635405552364\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40657454751841204\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40484194830987724\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.40316543314235753\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40154099675808697\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3999656998267276\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39843694328615553\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3969514640932704\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.39550811231618876\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3941044952873446\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39273843748588266\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39140940760359305\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39011479488535517\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.498838716312604\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.49560432785768194\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4925138410603171\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4895587138908495\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48672843364630364\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.48401331226278\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4814046566833543\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4788817119598272\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4764554608162758\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4741193778345176\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4718701704509109\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.46970079861617553\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4676070865450963\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4655846032373394\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46363052206601973\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.46174002929605484\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.45990915445946395\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.45813798797826333\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.45642738259954635\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45476753838035655\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6105149668804495\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6078807885742723\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6053465068696327\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.602913554602432\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6005692831291529\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5983118988015556\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5961378693405209\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5940306142561314\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5919901260087184\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5900137835673873\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5880995286886357\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5862384540941793\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5844314453407855\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5826769812445048\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5809693201060705\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5793018887466667\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5776705573678156\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5760766830362587\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5745200084499572\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.573000782537886\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4986591552979012\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.49601701528051106\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4934482734338079\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4909520948485556\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48852677745055456\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.48617180870650956\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4838848707618998\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4816586130302526\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47948937506049955\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.477369472423965\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.47529645514581553\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.47327186669857735\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.47129063040868435\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4693587002059838\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4674769681488922\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4656374382137785\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4638403943485503\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4620863470030978\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4603691595607116\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4586887625292062\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6006893872303952\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5974677972452769\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5943677787765447\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5913812067529846\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5885023789923296\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5857247249611062\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5830376516498152\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5804347695101368\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5779087179001318\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5754508719240604\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5730599866257251\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5707329389059232\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5684665277139862\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5662543469529857\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5640904298573696\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5619743784828661\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5599022595260268\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5578671469083913\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5558698876555401\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5539003476028999\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3902449412908536\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3864248167691702\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3828110891902281\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3793880003639331\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37613659092426344\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3730482995433554\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37011514431287573\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36732180990026186\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36466132343353586\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3621256097744375\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3597055699530958\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35739009728560844\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3551661383580683\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3530355097122573\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3509933034571193\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34903269701378187\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3471468635310372\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34533120068109247\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3435836556558144\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34190151926427964\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3660789621342146\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3637228931818306\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3614630438032713\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3592919463697826\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3572019978725806\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3551887586714485\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.35324845925181714\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3513772728354232\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3495698030013107\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34781915380189027\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3461227745886401\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.34447784894704936\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34288264749055863\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.341336415594419\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33983475493489756\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33837558972298803\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.336953150908202\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.33556607620705586\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3342139435550746\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33289502519116454\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5088491524558265\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5060497706968801\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5034064982736166\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5009026868859675\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.49852879325579463\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.49626687112448437\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4941004033376132\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4920233005278747\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4900334817750186\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.48811521948418457\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.48626089777124815\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.48446505059825\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4827241011865898\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.481031588443545\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.47938238731509647\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.47777504138516197\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4762071968649667\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4746721879195537\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.47316871240998787\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4716998682464428\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5747926718674587\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5717825527232098\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.568907324788543\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5661600111131748\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5635321742848425\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5610090485297796\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5585827734927721\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5562533458898364\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5540143013700847\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5518579386219922\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5497824355987891\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5477826380436595\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5458547333085086\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.543995349976688\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5421982077205219\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5404586388454544\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.538775297949312\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5371415978280382\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5355529594230644\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5340132408260674\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4497218894953823\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.44821362767185513\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.44675102786692544\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.44533272046699146\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44395620926415486\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.44261763522578396\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44131448909035176\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4400449464320637\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4388069438691363\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.43759900744855906\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4364200205733024\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4352677103952451\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4341412041367977\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.43304050636657265\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.431961275900654\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.43090340057343046\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42986497383591826\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4288441349910007\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4278401918613033\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42685262187072665\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4943087493304552\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4885229296249922\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4832067387120839\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.47829074555675505\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4737282111483847\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4695102813390638\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.46560659954174793\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4619786756337048\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4586023660006626\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4554464295325645\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4524968069036995\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4497396763794632\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4471537914939557\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4447235424854333\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4424369085309271\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4402823193351705\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4382474829837868\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4363213982380033\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.43449499440641015\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4327619273169323\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4672041943127569\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4621549232720063\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.45740968893426814\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45293623664986715\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4487134608899809\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4447250484393676\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.440960076262478\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.43740892805347426\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4340468468806291\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4308619242915026\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.42783419111770077\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4249582380882579\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.42222579977808483\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.41962279786039397\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.41713738512464\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.41476298369720555\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.41249060308335245\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41031303032498856\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4082238687495514\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.40621909253833133\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5278408325911506\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5252663268172066\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5227824968634044\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5203842298591849\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5180634066786698\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.515818482504736\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5136443330872056\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.511537582954817\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5094922942424371\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5075066268817761\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5055778891402956\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5037009272033983\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5018729629483332\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5000870461016855\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4983446658871492\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4966464246170226\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.49498887633793215\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4933702919352727\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.49178761276799254\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4902404566182474\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6960874370133772\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6895989952393683\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6834692445904463\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6776814142824988\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6722172866806332\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6670491660598743\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6621572783434564\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.657543172799079\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6531878272836132\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6490800887894275\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6451993903400093\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6415310043508317\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6380530737786727\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6347578706725008\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6316264052284837\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6286600055587426\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6258440963245502\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6231598593700075\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6205945293729895\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6181378271240239\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49664786916201115\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4937293485956087\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4909747432821222\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4883762306258794\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48591555255101193\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4835791571293794\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4813610124685119\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.47925296883040136\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47724071445919347\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4753225421970799\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.47349025049051197\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4717343985610848\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4700487769592959\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.46842728606787465\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46686228746168934\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4653514886716282\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4638909785142378\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4624770784155784\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4611068245317868\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4597778652865953\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3926010505933693\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38945048411457706\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38645876071674135\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3836204125305192\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.38091430442172336\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37833601356903485\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37587856061500036\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37353656095756554\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37130418188914177\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3691694081335315\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3671276505281825\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36517375308193173\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3633017049403337\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36150549715933966\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3597802414114972\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35812125976222386\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3565231254252125\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35497235837614427\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3534763390080432\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3520345131087964\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6374261276104445\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6354690246691188\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6335655209886126\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6317132743119396\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6299090377832697\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6281506628483499\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6264330990014997\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6247524055047853\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6231080421697207\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6214974648644365\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6199169472176859\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6183651592133923\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6168416974850255\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6153447196405342\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.613871868670148\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6124233437757098\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6109958741340484\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6095896207893003\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6082061663192349\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6068420077488108\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4269968437287114\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4241766264013846\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4215369169694543\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4190474873661991\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41668924657075723\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41445901156824927\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41233402539902364\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4103047818663314\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4083664617700191\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4065098267616175\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4047260401952119\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4030110811949704\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4013582225122837\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3997610398118568\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3982165502648919\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.39672440775832074\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3952803433734877\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39387495858213273\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.392504377847442\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3911675182789851\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.36969391466917345\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3679667224886421\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.36629771089613217\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36468830173758804\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.36313162505387553\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3616234757592588\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36016181918522944\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.35874246385656805\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3573645811186704\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3560241343791457\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35471882887009326\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35344704004467953\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3522070733916221\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35099525092303085\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3498102474069742\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34864974137631166\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3475122135220837\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3463986437813606\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34530610129527484\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34423340293472104\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.45054548036346265\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4461348037641095\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4419785971289243\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.43805894604688256\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.43436037410192585\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.43087164404750417\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42757794513377767\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4244609080724333\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.42151448712865824\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4187193098105484\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.41606731099285277\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.41356222928589026\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.41118294556845314\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4089162895681334\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40675359310759845\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4046886989491295\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4027152275188916\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4008224515101585\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39900547381517637\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3972551213786751\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5210951624525492\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5157763481321227\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5107236685233774\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5059138185620217\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5013269353578251\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4969534925894107\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.49279084655278665\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4888139809163271\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4850113252013507\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4813801851251188\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4779070035187719\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4745881019856174\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.47141686725094145\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4683779631031276\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4654613750977315\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.46266098975188336\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.45997148961832135\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.457387567925859\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.45490149507127525\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45250365736428255\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.511153843760549\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5079631641888898\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5049246646481469\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5020304252403343\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.49926487720031654\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.49662983639480973\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.49411397685927555\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4917041946654906\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4893928563934552\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4871713134865564\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.48503439171893564\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4829756476190389\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4809908043653504\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.47907385237664585\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4772213929705222\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4754274278180809\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4736857179359077\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4719937508493012\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4703496731970088\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.46874893294464437\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6070163998013414\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6034960407226044\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6000562467506885\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5966955651862377\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5934100113439795\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5901938990641622\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5870394053520038\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5839402835345828\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5808947804896534\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5778986215055363\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5749540018178978\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5720604861081485\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5692081661987551\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5663936305106068\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5636217220782955\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.560886516041813\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5581896219129769\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5555349921573798\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5529222390552149\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.55034585723559\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31303217175344383\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3098963812037524\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.30693338834058836\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3041357286868598\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.30148762143164104\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2989721710682454\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29657834614955836\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29429998224263143\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.29212801614944256\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.29005516062907855\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.28807324682296304\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.28617640295352365\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.28435730718847596\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.282610112850884\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2809304807448347\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27931921042766317\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.27776496744120294\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2762636722873527\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2748158648331972\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.273417464145705\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3991777691807795\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.39718710028737664\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3952794809874258\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.39344878225094404\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3916919773873015\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3900013590338605\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3883732864094908\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.386804385059797\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3852902216868574\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3838264379890918\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38241288638582493\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3810440260284226\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.37971729498782436\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.378425134268472\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3771573280134499\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3759307204677678\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.37473855824215396\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37357846785881443\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3724481001474985\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3713463246553423\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4738813331546978\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4715995292042086\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4694090525460057\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4673063610814989\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.46528034477578245\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4633271921733317\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4614422731761953\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4596243119916278\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.45786621461730215\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.456166626105688\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.45452301728224676\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.45293131560198563\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45139043369695386\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.44989643080597985\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4484447492922191\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.44703195021903797\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4456566703858113\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4443166067999609\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4430097435898577\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4417339601064203\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3097673893905857\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.30756274616254775\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3054778997275308\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3035035975120653\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3016321205110629\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.29985243582851845\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29815987265540234\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29654772675571434\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2950082647255704\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2935370071633594\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2921298517924381\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2907802536417019\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.28948308077332885\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28823775356845394\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.28704017951285205\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2858855048134306\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.28477149896580883\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28369371236676344\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2826514310001347\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.28164271508893834\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4028763892162365\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3998140813869915\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3969014408047872\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.39412525348467986\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3914714233863753\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.38892860529087825\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3864889658297328\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3841456287665752\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3818895670297306\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.37971498739890425\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.37761797237682393\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3755917807159732\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.37363107285924985\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3717285045255866\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3698864411444587\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3681000718087737\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.366366059522933\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3646832824160733\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3630451936042592\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3614487893912488\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3403189535888089\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.33865734685544485\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33705410288034243\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3355071503985762\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33401275387522844\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3325681324083923\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33116743882684263\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32980611038732555\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3284825152818027\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3271924106520121\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3259349335849765\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3247073238690281\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.32350699481693557\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.32233157392603584\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.32117909124386057\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3200500287335626\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.318942084272788\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3178552203187993\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3167885536116858\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31573790946106794\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.46750546651630664\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.46374778329789484\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.46021412956621754\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45688472043332773\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4537408105001802\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4507614012743637\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44793324438952686\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.44524278402387857\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4426815390800266\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44023642474737124\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4379008304370394\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4356622572537563\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4335092633574378\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4314459300636375\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4294643237980257\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.42755197723513894\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4257064920428951\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4239323650586017\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4222141907570557\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42054759207359693\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.41427334476703015\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.41250014534919277\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.41078337306037277\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.40911839570559405\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4075009343833577\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.405930078623939\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.404407113940529\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4029335231504831\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40149570103609145\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40009161890077105\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.39872028240806934\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39737989396386575\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39606798480524075\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3947851995044505\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39352976681086793\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3923004559732066\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3910959189987703\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.389913947182403\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.38875251101824365\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3876131919927753\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3048731477731689\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.30387860680590795\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.30290868382873287\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3019611839074996\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.30103553104343883\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.30013137097160536\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29924651859660945\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29837904061052983\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.29752865043088933\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.29669508034316927\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.29587765058337845\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.295074904916454\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2942876361268464\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29351577559164455\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.292756255180861\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2920073936000423\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29127000243295936\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29054369464629265\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2898294509121717\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2891255394707791\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3667056609878183\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3646641959713493\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3627224545673413\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3608743399367028\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3591150544964229\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3574358792441653\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3558314741401039\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3542955665801918\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35282198468455267\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3514090836621103\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3500534547738056\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3487509857233543\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3474990051023487\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34629308967217076\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3451300787569199\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34400880062092254\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34292640006947883\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3418801641525408\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34086559058638144\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3398809678549467\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.1828825494824266\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.18156500599168698\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.18033153350844167\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.17917442386176802\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.1780862068967225\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.17706228584082934\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.17609781682891765\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.17518647510197138\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.17432468088648106\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.17350852621726237\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1727339830550239\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.17199792129012254\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.171296954476716\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.17062830768267656\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.16998983440768728\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1693810575553297\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.16879815977615512\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.1682393324906169\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.167701121907545\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.16718300053013893\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2632474303624741\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2618657894974147\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2605464703049881\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2592866515086152\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2580816980827298\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2569287234270665\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.25582603948892246\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2547691868752051\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.25375451076051037\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2527800029476799\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.25184358793441675\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2509443879138908\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2500788906366525\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2492458469640615\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24844364779558964\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24766934618856717\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.24692039607694136\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.24619580129478047\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24549430223438828\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24481411594426106\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3241600200045188\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32206853181991724\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3200856357621223\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.31820287725312624\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31641084236925343\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31470284618837396\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31307465132746437\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3115194397249935\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3100308200942855\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.30860354287049774\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.30723338762175345\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3059128925034442\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30463895997154133\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3034091995758832\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.30222116639940566\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30107351441096447\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29996161246507297\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29888180783270685\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2978321548593517\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2968116782912935\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.25147734911149\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24994341230345626\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.24847379070479028\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.24706449751348353\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.24571151186203283\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2444131210189207\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.24316343157339135\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24195852660487288\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.24079550231567579\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.23967116242079517\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.23858555773756426\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.23753852744597817\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2365244916167124\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.23554079774167014\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2345866799823167\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.23365969186664165\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.232757606729188\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23187820777810497\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23102033185590137\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.23018239405545096\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34286744306099837\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.341319192507875\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33983924220825007\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33842673523724676\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.337075231417457\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33578105178559636\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3345405248682204\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.33334527147291093\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3321934752747662\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.33108164392901585\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3300068292595051\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3289652626406134\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3279543894794085\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3269723272625608\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3260169337079593\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.325085576993839\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3241770576730645\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3232896738917955\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3224212129197898\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.32157092369712936\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49516476986380065\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.49134670780986034\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4876859973168991\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.48418280446099576\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48082571526940543\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.47760465708572064\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.47451481216274294\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4715449300812154\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.468688922588932\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.46594946391750197\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4633151728191713\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.460780053182791\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45834094131102776\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.45598641692256137\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4537136062330645\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4515178314459458\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.44939331113027514\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.44733329766536206\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4453340540954442\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.44339521769018586\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.42572238697019554\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.42324374536750087\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4208682568268815\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4185907444189174\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41640533096019583\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41430337588673316\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41227472651060476\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.41031787193980834\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4084301671976749\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40660632873411606\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4048424873727732\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40313637953607573\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.40148425533895016\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39988105338260205\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39832573723678627\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3968139911843036\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3953428707007607\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3939112906228979\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3925178277068959\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39116068194666975\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.46076248930075603\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.458545651086341\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.45640164474941447\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45432728659017174\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4523141615322699\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.45035947542188204\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44845955927000564\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.44661460812627113\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4448192713354497\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4430711418193816\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.44136724997364096\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43970497589466123\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4380789146377273\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4364863692481602\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4349300963611729\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4334084849995831\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.431919687721784\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4304601599601187\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.42902635140540285\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42761807747302144\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4917888091012511\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4888006450528477\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4859527964380801\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4832393178912894\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4806490748803333\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4781714017281914\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.47580467267002297\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4735377041761864\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.47136386403696007\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4692770496038907\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4672725979519235\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4653445891370064\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4634886645916069\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.46169997492399084\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4599728516332785\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4583038366905224\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4566897604370958\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.45512787536031535\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.45361359603936\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4521442451052609\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.26211657334221705\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2609582747761494\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.25984782580822946\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2587806283660565\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2577531807460946\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.25676189003365\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2558031278600058\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.25487549024199857\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2539765903665709\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2531031277744934\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2522541785763227\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.25142977947207534\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2506254772686082\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24983905886896882\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24907064648202937\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24831877485849702\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.24758484175861184\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.24686629031045706\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24616039641907395\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24546751135005068\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.32478265127238815\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32201107915101673\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.31939442091565073\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.31691976379041475\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31457724978118407\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.312362405295156\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31026248000324075\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.308269058397478\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.30637366151838064\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3045669781501207\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.30284304770174164\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3011977751431079\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2996288611828248\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29812828493546917\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29668951815138866\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2953071701879442\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29397770234123166\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29269714590447826\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.29146318645078184\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2902721845093151\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37091348426438137\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3689427899654508\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.36706912695363475\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36528412304432756\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3635856133341614\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36196319826458656\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36041124241711925\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3589224125830386\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3574896497990063\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3561079013630054\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35477800758454825\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35349668986167915\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35226090893414386\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3510653420021471\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3499080964324206\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3487860321911061\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34769808402663266\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34663998869564716\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34561097324424217\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34460820389698676\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.30513553097691215\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3037935767188784\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3025092067444982\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3012774327851691\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3000945043472217\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.29895766734532503\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29786220722512563\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2968052706476081\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2957889565570291\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2948061252963984\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2938534457938366\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.29292982574466636\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.292033258187826\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2911614295505857\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29031274346788055\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.28948593273961887\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.28868271422941016\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28789830267862315\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2871316087140357\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2863818777396443\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.347963004497986\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3444921386472384\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3412646913847633\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3382525177908646\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3354353710362854\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3327948303570246\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33031448126574064\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3279833900354826\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3257970012991914\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3237348486223538\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32178443245339905\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3199366203134739\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3181830158552792\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31651551077386714\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31492746109088904\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31341297509932\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3119657778911376\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3105787018708229\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3092488326228341\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30797118154833714\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3960555939458935\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3946927940684989\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3933716112493034\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.39208946223521574\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3908449874482557\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3896348914299004\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3884558177473722\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38730382971007205\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38618060048524294\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3850835786988297\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3840110001851429\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.38296198963420525\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3819325425756159\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3809214737715042\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3799296648581183\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37895579862516854\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3780004479504251\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37705975131660685\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.37613354361998097\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3752210131170395\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.28454078757469775\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2813982130840642\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.27851101393646965\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.27585554738749507\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2734078190537572\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.27114950483562544\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2690575888990428\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2671168548565819\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2653107155936596\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2636261932361058\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.26205178116118605\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.26057624859928025\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.259192248914519\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.25789409776370703\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.25666985476951887\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.25551307687244224\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2544178471154722\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.253379161808409\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2523916675762104\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.25145541642661523\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3917664399943464\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38895563086736606\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3862762874280996\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.38372112921061463\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.38128042117835553\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3789458527119318\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37671033376797397\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3745677623702428\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37251276171225345\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3705379884831566\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36863673849858924\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36680568420542836\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3650397055695903\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36333631167653924\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3616908672815035\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36010065176576667\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3585591506381106\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35706422822304046\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3556130920640673\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35420311859571596\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4697933520646921\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4660714929992452\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4625361891950913\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45917093795080527\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45597149929095265\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.45292692206852647\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45002530110710837\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.44725617860646205\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4446106887041653\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4420827716512881\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.439665767651776\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.43735261444501555\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4351324140263685\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.43299655343447374\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.43094173945587044\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.42896385934126696\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42705698452562973\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4252161233119537\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.42343568928825626\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4217122305033565\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38405782824025353\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3807321099136684\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37756813216510343\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3745592826807185\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37169616191864097\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3689721078936922\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3663786817162557\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3639057917431968\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3615471958372445\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3592906610412591\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35713298209093736\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3550624226537441\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3530901484110397\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35120271833891337\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34939345387155685\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3476572478576614\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3459909934965959\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34439044163234167\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3428520004885693\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3413717331822865\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21487745138182252\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21353263230074981\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2122380450902943\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2109951574064532\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.20979781418956822\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20864381057230064\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.20752732349479527\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20645056750937757\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.20540910956463965\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.20439805805238473\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2034198330812732\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2024739490708934\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.20155745442345896\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20067523184402536\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.19982346409355142\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.19899553188611827\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19819097991101886\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.1974083014705162\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.19664642750534858\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.1959040101205049\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4162319203444753\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.41236590021238234\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4086729098075602\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.40514369331683375\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.40178211706037015\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.39857758946935273\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.39551736757591094\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3925976590529229\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38980992730986924\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3871430784032736\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38459187183454413\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3821485273283455\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.37980484012647975\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.377558771663903\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.37540421453684886\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37333490932954017\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3713448369879754\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3694291314782214\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.36758316942289415\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3658051904651177\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3088297728687375\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.30672726303589687\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3047227740366297\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.30280785399845733\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.300971557999467\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2992093789960241\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2975158617743944\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.295884415347072\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.294311617159139\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.292792104968023\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2913210361300442\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2898954147122428\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2885117083915234\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28716780411682635\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.28586046691726547\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2845869687323967\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2833431804511555\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28212992720266394\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28095047143534074\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.27979583709531686\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21622688068959098\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21479526593974335\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.21342314886048724\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.21210845389042104\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.21084759837629538\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20963445855001336\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.20846646058595508\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20734175728397222\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.20625716336144717\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.20520974556375565\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.20419761588937393\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.20321949656134886\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.20227344109756182\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20135644916841106\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20046723086276466\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1996046155787397\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19876730427401743\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.19795347244373826\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1971617790156884\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.19639098781221462\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.33512369612371107\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3326288338613148\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33031111697452076\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32815471648848993\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32614290585468386\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3242657684827487\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3225036834182039\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32084478550410966\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3192783878299251\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.31779529752902097\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3163872329609978\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3150503104030158\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3137743606079815\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3125545143630343\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31138457684347054\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3102597964535561\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3091767953622091\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30813267704941205\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3071228499434552\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30614487072703905\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3055251339687086\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3040351874811579\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3026051154898467\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.30123072581001964\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2999086188536078\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.29863564190448255\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29740637655240876\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29621722671583806\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.29506667340776344\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.293952651148083\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2928690646487184\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2918154048236883\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.29078917012138317\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2897879779565613\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2888110384125386\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.28785734814394587\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.28692322550361093\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2860092633407414\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28511473258737036\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2842386095795243\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3762470779884281\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37451307065466855\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3728523525391656\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37125792033016025\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.36972550043713076\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36825130638436643\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.366827809905907\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36545229989850564\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3641194774062869\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3628277723696862\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36157590010009016\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36036094972545774\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3591785284753062\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3580268415996987\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35690345008351837\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35580692902527145\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35473339089045763\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35368323166729365\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.35265493658052255\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3516468027587232\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.380667987216901\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3735878201192321\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.36705796593580065\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36102229327907\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.35542683707207523\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.35023135455320153\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3454100092883896\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34092549084229895\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3367417727816277\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3328433165700859\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32920765197698554\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3258173303338781\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3226599309363536\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3197069377963958\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3169492861651418\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31437981417265115\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31197198084032024\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30970969181351105\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30758198172745954\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3055812494420345\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.547329092136674\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5425027466078319\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5378501962263145\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5333601356296757\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5290172723206086\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5248181651615127\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5207423551996292\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5167964117559602\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5129708846856122\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5092686580856389\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5056877340949688\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5022113020916653\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4988343034037897\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4955477945949267\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.49234954648648754\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4892398763641329\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4862148505797357\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.48326518316209494\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.48038593486004666\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4775640430429697\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6808915089042644\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6713818419697017\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6622769230675241\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6535481772230443\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6452365554103555\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.637315123966507\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6297332227432799\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.6224683051555033\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6155148585605501\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6088486315379147\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.6025401190890521\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5965242873783467\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5907998025709635\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5853370732644924\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5801030935579254\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5751000677361033\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5703124788645497\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5657377152685761\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5613640903691306\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5571829929422297\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.43606985456399994\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4312074691096307\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4267056258370183\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4225350355211146\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4186635523919614\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.415065705402494\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41171436928199484\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4085882627651727\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40567180463038305\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.402945416794771\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4003857327886468\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39797527154672285\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39570265606972055\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3935587605253136\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39152984208959274\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3896042155842772\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3877721157497809\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.38602726944930665\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3843595493608485\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3827602571435384\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3887451630050883\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3851483422943343\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38179099597463195\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3786503521375676\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.375704142927719\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37292727448781887\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37030498152881214\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3677997516215512\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36541526564129095\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3631425288393245\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3609732732383506\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3588945693878438\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35689941228942873\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35498207155599926\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3531374704901852\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35135864663164185\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3496417113464796\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3479832078198693\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34637996724025816\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3448284311055013\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.40772060675219257\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4047032209021959\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.40183492369546997\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3991006371365587\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39650184402568156\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.39402476855915036\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.39165791322469923\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38939250894387945\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38722513843510104\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38514703025676345\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3831456378645965\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.38122308261635424\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3793724822930729\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.37758533510798176\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3758615177137343\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37419537472593273\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3725841265557863\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37102725467451514\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3695222752001635\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.368064941711483\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34053120823586286\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.338515923103354\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3365745031712385\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33470251255167216\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3328961146031191\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3311517094660403\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.32946701170857556\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3278369103104674\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3262595651880963\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3247321826113929\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32325110338949525\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.321814550465767\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.32041909269863433\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31906278373869856\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3177439289266014\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3164606656026348\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31521069357130055\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.31399388551507124\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3128086187474739\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31165470568533965\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34526574298725254\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.34256831846486774\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33997235830796546\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3374620930330232\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33504809480256614\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33272153993343007\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3304740633427889\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3282995039429031\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32620301477680363\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32418002705833837\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.322226027504452\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.32034016005672095\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3185232136342401\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31676633000080867\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3150657972905352\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3134146146893376\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3118147620316246\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.31025410527476527\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3087411945485741\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3072732321457144\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37380053685431497\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3716227286704426\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3694954268505909\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3674186998783486\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3653851868227118\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3633880058435777\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3614309493832648\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3595202382717404\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3576532869585406\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.35583272534761634\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3540485884834377\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3523003567119667\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3505900504920513\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3489174230848495\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3472784700737115\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3456761858429057\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3441028035460727\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34255876763975535\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3410438312593934\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3395596876591243\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3779738218041037\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3758869210592411\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3738754629012526\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37193837539220653\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3700723570092483\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3682734921822325\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3665408783326912\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36486750611178553\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3632486449694884\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3616837622759527\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3601713846944392\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3587065893397203\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35728534574375326\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35590564366028987\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.354563823484991\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35325596231406575\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3519817258553377\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3507391158535019\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.349525359174657\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34833721581561294\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3358031407101807\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3335040111918637\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3312952503085398\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.329172242377883\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3271289810969531\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.32516252529879847\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3232682292997686\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32144254019757523\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.31968199568345546\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3179856635207422\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.31634932096463825\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3147676793962029\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3132369483166103\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3117571745791999\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31032486602523857\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30893853391099313\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.307595106486494\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3062906507453425\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30502553227723783\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3037971000778142\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4624146755498348\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4591732639429331\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4560917206552348\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45316119359937096\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45036585940985274\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4476959989730432\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4451368997632677\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.44268028441118995\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.44031888508884076\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.43804666281669336\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.43585783325390937\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4337461124892725\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4317036798216\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.42972717509120784\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4278106888193577\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.42595180772625824\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4241404769552079\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4223827526628127\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.42067338187350234\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.41900914996251676\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3806182451199171\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3787611761637256\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37696138632043436\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3752170738296635\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.373520434371688\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3718685882259977\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37026186741545186\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3686970286810387\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36717288599402476\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.36568646745265265\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3642400145651672\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36282702052065874\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3614467911571332\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3600975299259169\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35877852292518564\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3574877342790595\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3562233110123332\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3549842514028595\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3537692736417575\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35257872623175734\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2264864661830967\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.22514144214382442\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2238526151104024\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2226176605865022\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2214320219277156\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2202928883308436\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2191960943643555\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.21813854757224324\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21711650363505264\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2161297131900034\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21517519983803057\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2142512373889482\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21335607081891167\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2124877392088661\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.21164500105324635\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21082580830588543\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21002932993032572\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.20925372539812676\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2084981366430476\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.20776137075517623\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.29966810330431226\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.297528017468245\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2954622588533522\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2934725690487137\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2915549011896914\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2897069877338456\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.287917831092892\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28619257927605823\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2845280091514818\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2829231705473921\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2813753587579872\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.27988111696524937\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.27843925148093346\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2770464580024769\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2757009942453501\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27440109430186677\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2731435032990395\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2719282960475995\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2707530271438614\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2696166599747381\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23786951066339562\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23686702273962285\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2358921262397528\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23494317397150338\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.23401955971469762\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23311761263369316\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2322372608501727\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2313758605358175\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.23053212656155786\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22970497495011885\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2288937293397477\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2280976487698027\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.22731646386104915\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22655135141886246\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.225798761741578\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.22505759414016704\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2243278308695837\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2236111255857735\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.22290487556386354\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.22220937664250495\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.30288830778635356\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3010467535433129\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2992638814599702\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.297537545035289\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.29586450502461425\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2942410038874641\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2926639849171412\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29113230939454393\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.28964136650937156\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.28819112323414176\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2867809974571023\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.28540729996210273\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2840674165771969\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28276074573046694\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2814855715802008\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.28024152185309925\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2790262505230702\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.27783924194978615\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2766792726740772\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2755452586964411\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5791684463828619\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5735296744110321\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5683676054992393\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5635960361105318\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5591825957964143\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5550794224172382\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5512572779262186\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.547678232702518\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5443159853433748\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5411503147897995\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5381649495801237\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5353413055955217\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5326617760957989\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5301095600354286\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.52767848343602\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5253588194080174\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5231398061248687\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5210124286105109\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5189708422736048\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5170036586694808\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4071609715346237\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4038907737263027\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.40078842096501666\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.39784376789630194\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39504204913322527\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3923749865704048\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38983177075945846\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38740370809375557\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3850822102947792\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38285585661257715\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.380717182196643\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3786514587042901\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3766626723416436\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.37474528786622646\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3728966046344784\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37110846060773234\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.36937917411247967\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3677034650197164\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3660740544165515\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.36449358170269847\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37202861976098645\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.36544409676231804\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3592989154639378\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.35354668014476215\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.34816791645926937\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3431396664907095\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3384471931505493\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.33404761158142515\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32991941544523773\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32604330013659083\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3224031026329551\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31898215158575044\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3157647292056761\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.312736523225551\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.30988459234353133\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30719081621916633\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3046374922648183\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3022249128979523\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2999405352469985\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2977702196725852\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.41987025046065485\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4183885657294444\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4169438556558523\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4155328712277466\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41415195450624187\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.412800309053998\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41147701439639006\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4101808177798093\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4089101699192923\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.407663438925344\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4064401442926715\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4052426729830293\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.404066311374531\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.40290937618240436\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4017704248114402\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.40064990032212183\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3995461219552853\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39845845498679733\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39738580072394136\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3963275353603532\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4354416274808229\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4322991693466266\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4292721221435608\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.42635079575053636\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4235292705650448\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.42080112100897105\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41816341343725694\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.41561025759019277\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4131364685549922\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4107379029902341\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4084133866019632\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4061537020713081\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4039596263591705\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.401826967086757\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39975309049023655\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3977334933250142\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.39576521000008796\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3938456034893888\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39197141849550243\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39014351116634777\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.394458912085758\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3838935709020256\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37411104947742624\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36505125583998976\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.356638107315901\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.34882997631196944\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.34155225144381607\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.33479651375758\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3285281857882675\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32270353465857593\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.31728249876318515\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3122370166140912\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30754223592505964\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3031632038139808\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2990748195184439\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2952530323921464\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29167540769411415\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28832643895847887\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28518984757718996\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2822495426823341\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31709771861621683\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3151487589856623\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3132815478867795\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.31149650099404547\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.309786455425483\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.30814722915913645\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.30657263648888194\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3050584810758826\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.30360126827215567\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.30219671589207986\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.300841209461708\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2995322093652735\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.29826496974950095\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29703760175327265\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29584603081301064\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.29468386138803626\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.293553671273792\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29245403578466306\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2913830964228229\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.290338973102669\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34437044178423976\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3401816218928149\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33628716942116815\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3326573440133468\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32926158151456536\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3260750111766476\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3230826164156184\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3202611345890095\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.31760045609290366\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3150881062981192\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3127104757364716\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31045116959137536\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30830448781966235\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.30625869643650305\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3043062613434051\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30244012711335005\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3006532245711847\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2989417411387079\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.29730113057302854\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.29572279518886774\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2836726333329045\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.28215467431816427\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.28068765372949944\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2792690884367089\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.27789510647980076\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2765617972625638\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.27526872265893293\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.27401223045130696\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.27278841187335934\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.27159586690933873\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.27043377732196916\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.26929822865984565\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.26818848382641725\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2671032353443864\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2660415797924914\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.26500301195063947\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2639865932420451\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.262989771659825\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.26201149201007967\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.26105047984272944\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3926954392331263\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38883900420880074\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38529364606218464\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3820250248465835\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37900035458047615\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3761935652938237\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37357799818420784\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.37113243514086425\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36884020944855556\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3666865565880133\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36466009059556825\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36274469698465894\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36092779910633355\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35919962959908563\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.357549089493275\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3559721493182504\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35445685620652245\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3530014146424591\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.351598169195032\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3502412614362889\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3541368531246162\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3523797264769639\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.35070917888104386\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.34911788575777514\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3475987410304157\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.346146871741637\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3447520582448047\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34341274338928707\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3421228549793352\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34088012403604495\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3396791294826699\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3385191519260074\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.33739726597734543\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3363098640039928\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33525513452387057\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3342298555183554\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.33323122043063363\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3322598219676677\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.331311663071885\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33038547585216316\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3204950283508894\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.31920191243342305\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3179588638673276\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3167650971096509\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31561351897974044\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31450143794318824\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3134267682517418\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3123866141486432\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3113770480783875\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.31039559112536813\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.30944028013130676\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.30850946098971765\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30760047683629677\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.30671347838118845\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.305846404235366\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30499757911973735\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3041660905650115\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3033509780047496\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30255059216748137\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3017636259943558\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2321003396242127\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23088719943828212\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22971399916146576\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2285798168348572\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.22748415398692845\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22642258946151775\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.225393429307774\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22439463395174222\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.22342474570260107\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2224819380179132\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2215650519877334\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22067229940768657\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21980247719893814\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2189548055147495\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.21812807863974715\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21732096518747157\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21653245042156916\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.21576518518835097\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21501456693370183\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2142795171956317\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3788260261925276\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37645847889249556\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37422619395032586\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37211715523049066\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3701207985247428\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36822957731765504\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3664349700551204\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3647216371604147\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3630737293742775\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3614954682241836\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35998010806552805\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35852551385411\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35712506907570707\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3557738310832871\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3544683842783347\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3532054453548951\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35198112183464564\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35079068965960525\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34963077446844804\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34850124055027326\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.28105391217298603\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2792438325568009\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.27754186077820453\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.27593492887564175\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2744102136287993\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2729633425368595\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.27158585788940726\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2702715661477481\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.269013958544589\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.26780931956918497\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.26665124879784774\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2655355044670311\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2644584239758642\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2634165615621832\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2624078652304542\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2614290216315172\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.26047804646268463\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2595523883468014\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.258649630731035\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.25776861554300096\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.46517258928654637\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4606829695424647\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.45650207631389195\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45259399822046187\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4489294626035122\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4454770942795782\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.442214576764111\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4391337870158347\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.43621601338329774\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4334517512949378\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.43082702819005825\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4283303599453804\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4259493984678659\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4236757972239617\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.42150127853197594\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.41941566992169027\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4174129252220866\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41548427453702325\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41362912448611044\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4118394410877284\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4936984558358432\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4908854874661097\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4881979811406596\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4856207030196033\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.48313661683115433\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.48075551812964346\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.47846578528759215\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.476260342537907\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4741371186853786\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4720892543482982\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.47011277073115026\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4682020790204693\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4663541845998055\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4645655135916594\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46283096639430477\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.46114999982900173\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.45951615063400725\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.45793097892370527\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4563890516658445\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.45488645051064086\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4457298307371187\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4420192746963075\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43847002403241986\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4350791321427535\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4318437307922154\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.428747114291057\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42577986297994475\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.42293816737084716\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4202097382181754\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4175880876729363\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.41505914802449073\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4126177297013385\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.41026928649124494\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.40799977670035426\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40580591837705204\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4036793072242486\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.40161710738491235\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39961872338968063\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3976775658019066\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3957896494569678\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2977435042267169\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.29617882745332236\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2946671414365949\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.29320409016236665\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2917880717819782\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2904161240729543\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2890853211418277\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28779313197510403\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2865391604242073\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.28531930637055936\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2841326694335994\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.282975955725009\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2818476137227906\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2807463706255082\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.27967106570855327\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27862118782826384\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2775951280400146\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2765897772170069\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.27560365888871374\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.27463711858196593\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3880653921625631\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38579868756796376\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3836021186926726\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3814698059752909\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3793990198087734\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37739019143307545\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3754404246298567\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3735469772815636\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3717067990644963\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3699169929428083\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3681730550013434\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36647408061349857\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36482324135189337\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.36321582436336086\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.36164909636840964\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36012184596440355\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.35863150848229447\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35717796992033823\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3557602444767267\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35437371065853474\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3384555250995108\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3349525119915413\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33166942071625605\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3285873168223554\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32568645874583785\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.32295173157945956\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.32036654109279217\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3179174594588415\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3155927008170065\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3133810057385049\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.31127282741754514\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3092692165231296\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3073593932623808\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.30552702509838586\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3037689612388248\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3020798057390345\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3004545496405217\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2988885490609424\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2973875635165552\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2959378634811875\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4041607416858629\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.40132426454151365\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39861221081266196\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3960158902951564\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39351286880348463\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.39110852527940576\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38880258266759193\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38658961404728104\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.384459363697486\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3824047328799554\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3804202920943815\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.37850229498849886\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.376649238109532\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.37485412671831086\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3731133671926226\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3714227249854736\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.369780705832012\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3681869318762826\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3666388665033563\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3651319858994987\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49457598384963186\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48215935469138427\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.47089239299781943\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4606384883327969\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45129187863634557\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.44275297429442134\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.43494370692139117\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.42777736892214335\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4211826690251328\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4150885940583885\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4094426432741467\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40420487048307796\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3993393433010921\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39479808800196425\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3905493457446195\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38659108766355654\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.38290088655866655\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3794438784682218\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.37619415869255846\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3731326654932635\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.45655060953177323\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.45419115174209135\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4519107972245852\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.44969962492205934\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44755750743273004\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.44548299847237727\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44346949618037507\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4415132977001136\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4396125939143463\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.43776294656659764\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.43595953157920814\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4341998115039587\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.432483821221125\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4308073822375945\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4291675137014888\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4275620706763248\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42598962633545506\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.42444939320591213\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.42294063202239507\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.42146013861035914\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4925957005778754\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.48828484456207255\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.48423260795435225\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.48040191053579073\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47676271287721644\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.47332539511216604\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4700648059735313\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4669628959202933\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4640058745412509\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4611744140809644\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4584654988267163\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.45587085980159886\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.45337376773656435\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.45097321826155234\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.448668590489009\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4464465835911389\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4443019094900118\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.442230337248119\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.44022570825080415\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4382840686782152\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37882925760500397\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.37612949299205234\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3735265629902849\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37101323084120075\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3685851010109149\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3662363743161673\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36396416739266535\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36176607252861087\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.359636538515005\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.35757191795953785\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35556993878166926\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.353625887613639\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.35173883525584343\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34990694995875626\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.348125964673548\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3463961798714307\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3447161343878897\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3430817682686245\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34148864506386384\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33993611819168346\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34285069045009325\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3406646433166137\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.338560419089871\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33653426009330906\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3345841816492854\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3327064181209383\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.330907167686134\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32916894087920673\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32748911663948177\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32586412703685597\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3242922490059804\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3227713524537211\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3212997901297194\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3198757292495231\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31849743829133625\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31716071722879\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31586304586331027\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3146012584760639\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.31337372748405334\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3121799665964168\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4089056785624429\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4045383744642474\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.40037226304641815\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.39639869330908406\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39260374800628145\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.38898334267292195\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38552420085054856\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38221877459539033\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3790595422472768\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.37603656784244366\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.37314378811421633\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.37037305319662606\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36771889433727756\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3651729791963285\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3627281197045493\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3603775287041407\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.358119641196164\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3559429784442726\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3538482931034963\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3518257228408508\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4702244118911382\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4673518205497522\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4646274333483986\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4620387264142174\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45957082806172267\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4572073566816688\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45493995461409587\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.45276719545053046\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.45068010172668255\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44866924859856516\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.44672937073875785\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4448539737752698\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.44304048728211043\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4412827594090189\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4395756926695584\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4379172079181304\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4363047316927875\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4347326476713934\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.43319937730200364\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.431699542026449\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.42097917802448315\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4143423338046835\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4081186690815568\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4022824077496449\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3968175758193829\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3916852605569534\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3868511109247451\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3823022390338676\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37801645665257333\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3739844803367098\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.37017548749874407\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36657115395891504\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3631593306905702\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.35992449424708256\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35684927989835924\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35392419047487583\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3511427417166085\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34849013941961304\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34594652526535696\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34351341538537805\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3395040559859458\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3377417685902754\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33606510102412923\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33446703175291786\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3329396641946646\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33147658589041634\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33007243260919905\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3287202915130627\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32741553360342457\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3261559157482594\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32493820543054575\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3237593116978268\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.322617995759927\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3215120800119922\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.32043923782370437\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31939446693214446\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3183774906712085\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3173853624801273\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3164183438407754\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3154730218815739\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19756527254716183\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19612965160697068\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.1947434318384714\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.19340327621820874\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.1921076359160306\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.19085528217310316\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.18964320262398224\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.18846821586365115\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.18732798928068017\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18622131524623406\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.18514657862206652\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18410203457154445\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.18308642535268288\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.18210093518520046\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.18114567020512212\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1802150769727241\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.17930855661472822\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17842542452933302\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.17756389970959588\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17672320388846954\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.22802671222212068\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2260287408715138\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22417183993951176\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.22243195630162133\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2207942807297179\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.21924777672764909\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.21779210680840622\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.21641819342064172\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21511820146946103\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.21388810747566292\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21272362186905355\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.21161588939966164\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21055954928993628\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2095509741447307\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20858856441031057\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.20766589561249743\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2067799465184288\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.20592704818915955\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2051047664967291\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.20431127247749756\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2645919495176653\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2621915088108331\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2598905476944014\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.25768633127401497\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2555710385671799\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.25354234262019776\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2515906801536344\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24971314088289084\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.24790592752106916\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.24616662246083465\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24449022529952713\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24287679292863082\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24131912904902975\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2398125484421339\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.23835686064298792\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.23694517587616107\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2355805185734554\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23426061528195047\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23297629382104712\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.23173143566201648\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.30526758723223\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3020072768349008\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2989591568096129\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2961019315159944\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.29341632881649904\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2908885570701138\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2885084685590671\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28626225866113697\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2841409289645397\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2821349085812346\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2802358951341704\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2784365043409103\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2767270456692308\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2750997367543445\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.27355184486116757\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27207679435843657\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.27066781400734674\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.26931935327238576\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2680267476829988\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.26678580017553094\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.411187118660939\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.40773111716367716\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4044934623263683\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.401456176450378\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39860178427884635\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3959164539265438\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.39337848923789226\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.39097631639688585\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3886978083469698\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38653316989977915\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38447793454715173\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3825139829720461\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.38063849486116796\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3788451651657895\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.37712505951046804\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3754741198934024\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.37388759099094887\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3723591474481066\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.37088510384152484\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3694646400091321\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37899599594014066\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3756658008602024\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37253816479624235\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36959463925416336\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.36681609092906947\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3641773118954039\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3616865796977681\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3593317538927901\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35710642741422843\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.35499897858740287\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3529990391839944\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35110188227740013\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34929156970444575\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34756708239776024\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34592264579137405\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34435342845057126\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34285411549487205\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34141720395831754\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3400387426460727\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33871742672857613\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4327423200816304\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4279319436950011\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4233556565778188\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.41901034885865557\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4148816656273615\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41094098921537603\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40718101482232005\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.40359744592650304\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4001721789786812\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3968917398465726\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3937427526149613\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3907202396555304\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.38781410105363\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.38501920426087655\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3823229351120434\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.379719339533319\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.37720493066728567\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37477675323622583\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3724269803400604\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3701483944285672\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38939405953471384\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3857105741806336\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38224775228526\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3789866842943816\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.37591116634595995\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.37300892288916754\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.370266153220551\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3676634367399577\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36517152209614445\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3627989366471598\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.36053675204960145\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.35838169966108513\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3563183962039226\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3543333026287646\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.35242434415319035\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3505879962634779\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34882140650453675\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34712274971866297\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34548452499710214\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34390362734668023\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.44141829735472465\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.43818273214557346\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43507820561195587\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.43209599685424116\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.42922787503163484\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4264667158232336\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4238078871941626\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4212435755961871\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.41876391584682415\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4163634383144217\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4140389690658251\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.411789801375977\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4096151825319079\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4075031748051995\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4054512841749428\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.40345048310794135\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4015053231298054\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3996154771211583\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3977665129866703\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39596193987742323\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.35988171981811956\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35882163153389124\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.35779227070120156\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3567931331821297\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3558201173665272\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3548701609889775\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.35393689808797835\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.35301471894893216\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3521125823871863\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.35122833161722333\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35036141066721366\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3495106701704645\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34867477145393977\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34785250961550995\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3470437833535746\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34624868848223334\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3454673437962367\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.34469707941790184\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3439374261862874\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.343188092106189\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19958050090648377\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1976242485278606\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19575884562422532\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.19397796055594319\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.19227361963892609\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.19064106154292085\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.18907361716840704\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.1875694046872884\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.18612120908920343\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18473128541428893\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.18339519267345203\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18210889469398273\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.18086981048600292\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.17967488635102996\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.17852053637005372\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1774051705600307\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.1763276321455443\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17528648944031228\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.17427953895876996\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17330521629988976\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.303259818518699\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3005280303147171\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.29795497372186064\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.29552642790000794\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.29323382826063665\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2910692115226834\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28901857209848775\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28707514264226575\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.28522845739290675\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2834630347392548\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.28178334642425296\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2801800576346787\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.27864915547190505\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2771851049830224\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2757842798770993\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27444166782280593\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.27315286808336225\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2719146353152442\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.27072295804966284\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2695744847047352\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4301943266616156\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4284029079825026\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4266618862213605\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.42496550851097525\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4233100208844728\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4216928501082556\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4201118748384172\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.41856594244918044\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4170509680296871\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4155601475821181\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4140970601261218\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4126589610344329\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.41124476888043376\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4098553157441641\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40848913501776807\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4071460205872599\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4058245400763406\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.40452180930381254\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4032372785688809\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.40197041072656714\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4329957340026665\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.42931173979852144\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4257684659996851\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4223592681913836\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.419078393102205\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41592581577464605\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41288892801871296\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4099613938162924\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4071338386452622\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40440580438904616\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4017710759572743\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3992235524872507\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3967545244195938\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3943867928957829\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3920949553876315\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3898731302019429\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.38771965258713037\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3856328565982045\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3836084534759907\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3816415979143464\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4179562809643915\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.41599239643458463\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.41407607108786604\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4122065775983639\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4103847551138782\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.40861251311615054\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4068724949973278\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4051713627876964\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40350966480299394\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40188934507380936\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4003019613168853\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39874676508847673\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3972226447512537\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.395730090390522\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3942646997932071\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3928260387613706\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.39141339860386226\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39002600041574664\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.38866073291192776\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.38731969469187755\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2749677228834105\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.27343033915372467\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.27196066398761504\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2705502598613615\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.26918781234975736\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.26787763878282733\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.26663642397872034\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2654422091485357\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.26429111672220795\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.26317796029424095\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.26210164174943573\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2610594628258319\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2600487397900332\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2590689494176269\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.25811638084866373\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.25718640215713584\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2562821168892515\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2553975801031792\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2545310133727583\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.25368326463520796\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.27103708323951803\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.26827849603628573\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.26565742110216206\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.26316369017436797\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.26078665287708025\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.25852065914820954\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2563594096128674\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.254295088567549\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2523209641516394\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2504298580429843\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2486179746749848\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2468804912138352\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24521336063190724\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24361278540119566\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24207392759936552\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24059301576333164\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2391684097600607\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23779479477989535\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23647041716546702\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.23519191884175372\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.46493172142378425\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.46290441928225995\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4609378128278145\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.45903214354172595\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.45717700148253004\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.45537244157292833\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.45361494484318987\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.45190025256260297\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4502262011349398\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44859013124619873\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.44699123701120147\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.44543371795960607\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4439106948749646\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4424190858673577\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4409596058387877\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.43953008627687884\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.43812671831437966\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4367480149355364\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.43539563776838675\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4340642734354539\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.353690561179056\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3508144194168861\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3481052789381316\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.34554990052804047\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.34313108989271546\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3408350673811794\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33865446491977524\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.33657720463175556\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.33459542984599644\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3327007852809661\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.33088636543689354\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3291479291565902\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.32747902537596885\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.32587576280291475\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3243331247768887\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3228458385795146\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.32141016442837944\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.320023060528306\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3186894857073436\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31740055070062745\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.39120305401365996\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38664189726643344\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3823328004234226\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3782590954303571\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.374399828639413\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3707329460866642\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.36725325995691527\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.363945539192787\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36079850729308194\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3578015680746349\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35494461641198494\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3522188492910627\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34961475868407804\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34712645859537034\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3447346997406296\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3424422119335656\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3402447130335982\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3381320577588805\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3361027515010516\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.33415318426545304\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.42312249510840116\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.42133999562642516\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.41962509995157915\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.417981433011248\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41639413712901646\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4148614135264048\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4133795636954817\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.41194610873956083\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.41055860821593204\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.409214979662946\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.40791347381645277\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.406650815828727\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4054264529224981\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4042382607876236\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.40308355640514426\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4019591867935326\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.40086279433585315\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3997929683652878\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3987485989382803\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39772665330159507\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4148228608779363\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4128591346209074\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4109405950252263\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.40906587790085974\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4072349530316253\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.405446234903491\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.40369684290912417\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4019851258565957\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40030960477373545\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3986699281836231\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.39706345091180273\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39548987301589134\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3939484828550337\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3924381829713856\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3909573625515257\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38950479986939496\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.38808086593733543\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3866840044169191\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.38531389116548403\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.38396679103398346\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38050973463865273\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3760204975269006\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.37184812696835756\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.36796473702354615\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.36434210139678924\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3609575526877672\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.357788027054299\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3548148677574966\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35202370513220094\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3493939945166612\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.34691878476318555\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3445860191587692\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3423784524278469\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34028507396122337\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33830012058693687\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33641116654872427\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.33461101871453447\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3328924226434865\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3312471445183449\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.329665414612335\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5234218592971445\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5197051424446305\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5161996722045725\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.512879992123057\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5097330425804335\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5067486857896792\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5039144562761477\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5012141528164683\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.49863384711397063\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.49616368338208816\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4938023112058051\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.49153792996687035\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4893631200743308\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.48727273428737133\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4852600946166701\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.48331945845019464\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4814479988894833\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4796367270270311\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4778800891916358\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.47617940995574654\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4302471163053258\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4285937616244916\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4269928752747885\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4254367500775442\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4239218441198468\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4224455797721876\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4210045851423641\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4195956181813092\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.41821783253519834\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4168688256506674\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4155478019068966\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.41425234085941337\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.41298101967531764\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4117329685452047\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.41050121511212745\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4092892511911336\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4080952829301234\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.40692027124795394\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4057635438311935\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.40462258578200105\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23660534297126135\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23456935960254485\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23262692865669515\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23077111436362155\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.22899372982169663\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22729238005540928\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.22566383678228785\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2241044298691364\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2226093944138576\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22117321085190988\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21979108085506416\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.21845900852125644\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2171756049682567\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.21593813401686052\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.21474514447640247\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21359350800783883\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21248133743282535\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2114070237103171\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21036786834487342\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2093627380631116\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2739749794219142\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2723115106030767\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2706979935288417\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.26913038037642\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.26760475086360214\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2661193251930208\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.26467233130180645\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2632613431811637\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2618855301382863\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2605436241882695\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2592335295336402\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2579544281400123\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.25670537595448917\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2554847787456369\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2542902110691802\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.25312169803950035\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.251980289153511\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2508647807014891\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2497727814652996\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24870305204521162\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.32918944574469805\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32732209447863597\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3255278248644471\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32380152266577444\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32213979232912837\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3205384437399166\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31899457721284624\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.31750440426769944\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3160696534033661\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.31468153774214636\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.31333733821318366\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3120370469106669\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3107753321401162\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3095494436669636\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3083593289261479\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3071984773687484\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3060672349510666\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30496183243156844\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3038829639619958\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3028281565604614\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.30681234309709426\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3045419784344854\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3024000172527286\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3003756991009833\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.29845946678468166\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2966358963877123\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29490347248687987\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29325599212935116\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.29168615424603866\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2901878954673578\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2887548843785921\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.28738387271912313\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2860686503114761\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28480502667679974\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2835906566621136\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2824218254790145\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2812938450225789\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2802048223297945\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2791517743328982\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.27812979008247585\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3244731355469914\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32127528250517\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3182444745141927\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.31536618453806503\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31262804979143777\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3100233623096183\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3075371954133507\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3051684914961746\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3029129417160832\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3007601325003499\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2987047960555261\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2967422030488447\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2948604525337993\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2930530188736847\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2913168158026273\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2896486782744957\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.288041093518938\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2864911883100144\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28499588811325416\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2835513578038511\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.32308693329589383\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.321257507697607\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.31950156856434697\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3178130575756881\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3161899949467686\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3146264520015965\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31311753489364413\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3116597379774997\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.31025479979045917\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3089070422784207\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3075987167758171\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3063274503198233\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30509190793176383\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3038885652526008\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.30271584375793686\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.30157179700620584\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.30045547142500234\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2993642147246598\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2982968651310438\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2972524907498727\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4211996158008141\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4189470264569219\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4167800905325014\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4146912060636465\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41266739723521983\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.41071253638228133\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4088242261387935\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4069996424093931\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40523681333870043\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40352847844088524\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4018691374388966\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40026055755250073\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3986967214090988\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3971770529048171\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39569872229858016\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3942581531750672\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.392852909085018\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.39148014576516493\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39013614112931405\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3888221301542194\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.38622263139473295\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3816955699152467\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3775074711368325\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3736078329099999\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3699969009237261\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36663126767235976\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3634812278353675\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36052229985381135\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.35773655616904965\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3551060859494899\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35261599607022365\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3502551829257333\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34801219287909757\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34587683084962284\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34384021302466006\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34189402834848515\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.34003107209305106\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.338246389466846\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3365289051304429\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3348758467609849\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.36452548644440425\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3580629621438717\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3520638818438175\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.34648547459109447\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3412863132893742\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3364346341753961\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33189871280025507\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32763810712284824\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3236311320432282\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3198545479041528\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3162960863221048\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31293830324426664\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.30975975962614216\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.30674679404741684\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3038885989503343\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3011745395076024\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.298591477262799\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2961380338410544\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2937997937283684\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.29156578784092335\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3465465476432842\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3432439495642333\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3401353483200783\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33720414385793074\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3344289408677702\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.331792704636517\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3292874126856344\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32690489964201014\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32462747877761544\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32244665503397907\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32035580715840767\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31834775716066255\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31641365667015736\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31454660083777464\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31274372608947154\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3109956906609701\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3093030962965658\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30766157039899306\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30606671448320305\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30451723912949935\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2523943756540873\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24981782825945553\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.24734907013832097\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2449819980379866\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.24270782249347442\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2405221713200828\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.23841900525939014\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.23639135528129124\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.23443620971223258\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2325501130708412\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2307287770006004\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2289657027373725\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.22726022334712503\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22561084576047263\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22401245747919427\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.22246197753165092\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.22095722869126988\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2194958072380901\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21807556588536\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.21669346164813813\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.40516136786972134\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4014065664608312\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39781645655565434\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3943865791220069\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39110357695897596\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.38795212858173456\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38492704052360005\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38202102987523384\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.37922154967386557\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.37652576199115717\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.373930271974129\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.37142776886232093\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36901499369324436\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.366685579585191\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3644343370759391\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3622536031260225\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3601409467114164\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.35809605754100304\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.35611174077889685\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.35418336259533423\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.24283479589803675\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24070030464359632\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23864410103585842\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23666299380099176\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2347520472537788\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2329070133916256\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.23112409563180397\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22939990568131624\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2277323680036164\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22611888820538412\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.22455863480689534\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22304551905643416\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2215757198089634\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22014636276320607\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.21875804582882002\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2174086439057532\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21609666848917175\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.21482045909956804\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21358026882206177\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2123713982064075\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.1861363885944795\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.18516592731369425\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.18422491845096367\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.18331187145690053\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.18242532192853964\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.18156394463328343\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.18072793958452052\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.17991491767982026\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1791228853987055\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.1783513375675051\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1775991534329618\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.17686546414732954\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.17614936392773337\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.17545045985562635\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.17476774732193548\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.17410021618376076\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.17344763304411537\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17280884807098446\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1721834435316103\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17156978904961526\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3909146469570694\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3861860921824281\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.38177134604836954\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3776285340684517\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3737367458946744\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3700829960304267\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3666502995828149\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3634189283160595\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3603757285968483\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.35750185782387706\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.35478696699743795\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3522229838097539\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34979986415908904\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34751068825189424\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.34534571281085874\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34329331868927226\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3413485121756789\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.33949827888305084\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3377350269475641\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3360489906101213\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2647917687673432\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2620017067530733\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.25937478605350256\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2568946681605505\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.254549035326805\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2523264472767446\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.250220125604047\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24821859548632552\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2463161149958153\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2445039365431098\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24277580227972054\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24112746343441233\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2395545959818689\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2380490755745792\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2366044061110999\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.23521836966571025\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.23388798261857288\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23261053381650346\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23137782330804121\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.23018824882035277\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2982042354192673\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.29512575257086887\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2922115638035416\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28944512194250116\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28681383936789756\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2843077635479929\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28191971673352245\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2796385477623805\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2774609637371893\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2753816999534907\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.27339127027615473\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.27148518582788395\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.269655136056408\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2678947210830634\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2661990850046986\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2645649317744167\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2629883432629331\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.26146535709457996\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.25999303285721725\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.25856875182649575\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2419677066179906\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23860868935541102\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23543264213565918\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2324295359153054\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2295845468488268\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22688606408363315\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2243283315211229\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22189901074450094\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21958790622269722\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.21738854674420383\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21529339394076308\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.21329682473625922\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21139077957129992\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20956986625233853\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20782920469610205\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.20616577121773466\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2045757688735882\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2030510073728105\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.20158451654214282\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2001777641539726\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19808320035921695\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19665859445134798\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19528743465500287\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1939665875483568\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.19269450836841945\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.19146875099472957\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.19028779128073833\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.1891500504745584\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1880518186781594\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18699212424749506\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.18597014250050858\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18498928745407056\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.18404203419135506\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.18312574323648012\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.18224023285569574\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1813819275401574\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.18054906210860533\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17974133587601512\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.17895714494137785\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17819487002947182\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5689592667673098\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5616623663151377\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5548787140863698\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5485630164196058\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5426701631569497\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5371489036781204\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.531980236794339\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.5271343182044625\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5226020084293884\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5183585033362806\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5143649967547319\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5105960963580276\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5070396487774953\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5036806164548362\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5005076946993321\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4974998927168963\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.49464227987551035\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.49191954394292814\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.48932102744957096\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4868424997592717\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4259843681339884\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4236370796615404\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4213775909437223\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.41920357869205044\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.41709694858889074\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4150634669294435\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41309849327002574\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4112001267454382\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.40935950869910853\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4075733188358941\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.40584165202305034\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4041611925244642\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.40252922225656346\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.40094405213010337\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3994029022773804\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3979029076299853\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.39644285079027847\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3950205754640515\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.39363485441223023\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.39228323362067175\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4773644076684015\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.46746988506822895\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4583763535292116\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4500197835128304\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4423343725633625\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4352574801212352\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.42873958846871674\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.42273934462043017\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4171928470234775\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.41205224801081475\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4072914121297364\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.40288677269890116\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39880082973828157\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3949930954017708\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.39143758143748153\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3880993220783333\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3849659019856456\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.38201542393049487\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.37923409419798304\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3766087656378816\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19861185011399635\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19728722534382154\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.1960233232577498\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1948152321005224\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.19365868358125626\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.19255088327307285\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.19148811508526553\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.19046714881327048\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.18948651081355566\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18854339470499193\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1876354426478069\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18676025192522938\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.1859153433204206\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1850990739226926\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.18430940845029525\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.18354521301700438\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.18280472743656495\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.1820875780218491\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1813920553085985\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.18071856716721435\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.516315264723705\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5133217317960304\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5104494043972784\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5076869324378993\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5050268393002656\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5024612539378525\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.49998197539817024\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.49758524485467104\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4952669893962748\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4930219131622827\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4908460763175308\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4887350432120352\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.48668004960532163\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.48467895749083956\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.48273082856139754\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4808315835936275\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4789796989424723\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.47717012258172087\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4754020822393976\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4736736224216522\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6009496398538283\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.597775921648064\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5947305878439358\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.5918004648687991\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5889800315225702\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.586261342813962\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5836467859598307\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.581125997715136\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.5786607458207889\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.5762765059038\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.5739656915868421\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.5717201298088931\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.5695390101376445\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.5674206318023148\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.5653608366202465\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.5633605842467894\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.5614164690026857\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.5595205188676292\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.5576697840395901\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.5558627435240643\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.30080912655640657\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.29711705376458813\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2936947841138084\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2905155807511586\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28755848253616084\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2848008547541069\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28222535713031455\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2798144663797305\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.27755782506722515\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.27544006999941495\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2734447593548571\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2715649948467914\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2697926395117639\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2681178477577474\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.26653093232866387\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2650254838603828\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.26359546169992404\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.26223202709103144\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2609304702554458\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.259692294701487\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.45861292757618\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.45120794532571545\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4441793238471066\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.43750848002376275\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.431193844813292\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.42520250532554443\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.41950949396822645\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4141022307423431\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4089618550707066\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.40407509280524545\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3994259590042808\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.39498970159235625\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39075842359990487\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3867246990544405\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3828721976422546\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37918964652444526\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3756839703355954\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37233685078877166\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.36912939455904237\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.36604999275954364\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3351945828435255\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3309516201654053\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3270014521330794\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32333769609543794\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31992828264462647\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31674971747528813\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31377738960477897\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.310987307639234\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3083683895043496\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.30590538900252157\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3035817260600493\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3013860777394295\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2993072269964584\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29734703082393343\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29548282388297414\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2937042506121784\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.292003766371852\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2903751888953658\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28881183656756326\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2873100583312976\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34849533426984003\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3449388585590818\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.34160788624815686\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33849076432405006\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33556142990575927\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.332800641717166\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.33018757889758876\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3277212118983238\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3253864500764121\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3231743947693838\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32107412427825976\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31907415116287635\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31716792501598867\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3153502112359806\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3136130803567667\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31195138895419855\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3103486220849822\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30880870150160966\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30732590244854857\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3058971699368898\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4334675180039574\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4319070543355667\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.43038188528864496\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4288888972853745\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4274260455657457\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.42599269197247314\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4245865991443629\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4232083147114007\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.42185678510412916\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.42052727386766975\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4192184292933868\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4179298800539527\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4166604426783078\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4154093150532514\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.41417680654884204\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4129630712040844\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.41176513550774685\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.4105818735394164\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4094124355160571\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.40825544533330116\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.7388335932943048\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.735720512818101\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.7327043110463005\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.7297763089251237\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.726931419507933\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.724178041346421\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.7214987724380503\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.7188808164449416\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.716322272029526\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.7138233462414457\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.7113750741966884\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.708973211717104\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.7066137245514312\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.704297250357748\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.7020194840159153\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6997784915465235\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6975737304276011\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6954009288500856\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6932603463009775\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6911506530811959\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31784649711367025\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3157617507577538\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.31374423302943333\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3117948880550451\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.30989485010711715\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3080536161234744\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3062742907295306\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3045456017260336\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3028665332534204\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3012352622502779\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2996496340357998\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2981071453773966\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.29660564565672054\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2951441421134149\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29372542553917613\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.29234631322777227\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29100028102305364\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28968636853961477\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28840337765495017\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2871505561719818\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.49930690359136376\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.49215538810731857\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4854247591709847\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4791058894041248\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.47314162919358105\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.46750478234958975\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.46214322765373955\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.45706518854018874\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4522500660404824\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.44767508122763566\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4433219055989821\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4391713187007368\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.43522311436068534\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4314248858330382\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4277825793415574\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.42427455111916423\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.42091302728525903\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.41768621746172163\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.41458834429757024\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.41160944141694966\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.35273219388570115\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.34855345844526175\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3447037028044099\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.34115026110233565\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3378550822335388\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33478827392262256\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.331927183803138\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3292504918651715\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32673582071803087\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.32436982115931207\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32213792691778004\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.320025313736949\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31802430281440563\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3161227945912656\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3143104791603433\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31258104373085516\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31092566585298903\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.30933918055655163\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.30781465753069803\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3063498651240984\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.22908657212618827\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.22708612000508194\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22516385386875998\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.22332390005312902\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.221561306259645\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2198708778712478\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.21824633581990416\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.21668464712481744\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21518175063871026\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.21373463698611891\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21233928923882306\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.21099552706489383\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2096976894352204\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20844227387170775\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20722658438505576\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2060478439468781\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.20490398030737467\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2037934285418963\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.20271456350874634\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.20166347854860805\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19528235489842077\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1937316907782098\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19225001697752914\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1908256654627431\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.1894546065507373\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.18813428520681413\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.18686174921647972\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.1856333425654726\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1844442028671985\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18330103524283034\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.18219654498339427\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18112909064341556\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.18009697079469986\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1790976815903192\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.17812914727891188\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.177190221907766\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.17627985111827404\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17539613491091124\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1745387610385125\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17370747122935037\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.32369681131558814\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.31965930494641415\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.31580066745207813\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3121376092606729\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.30866111366882576\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3053570376545113\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.30221587751511914\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.29922603054295693\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2963816999707616\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.29366688571565225\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2910842333232854\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2886139380218664\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.28624568414937934\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.28397014366327517\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2817881095930601\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2796941950199431\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2776816224086513\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.27574486249653146\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.27387864124664585\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2720826328453819\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.40356529932197305\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3979622606314096\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3926453280582276\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.38759240039677023\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.38279015360982277\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3782228362943373\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.37388028259058226\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3697490106568319\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.36581770470633884\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.36207399705932747\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3585032948857213\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3550848746299864\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3518219247907004\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.34870282477575554\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3457202846936467\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.34286646773596585\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3401307501628289\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3375114311696078\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.33500234317771016\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3325952645524577\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23695468889320062\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23525347418080858\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23360791173632323\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23201365634943763\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.23046911997135777\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22897074257079497\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2275169590150508\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2261062532512938\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2247390723227906\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2234151027145518\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.222127337026052\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22087437688609013\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21965239573754125\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.21845930217501758\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2172957942612863\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21616008748142163\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21505325523740376\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.21397229391068856\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21291615629771266\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.21188500572032412\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23353944029117035\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23214536432689364\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23080193606906382\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.22950655366367695\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.22825184926631226\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2270370401483769\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.22585894869357928\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22471549781535766\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2236047914907725\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.222524842020944\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2214755096806609\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22045666243879997\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21946197309480345\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2184844607122742\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2175308304602583\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21660034222204547\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21569120103587908\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2148023468646066\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21392794650270122\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.21307219520569454\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.20100281465182573\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19932386037287064\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19771405833831712\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1961695346519735\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.19468524819332944\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.19325623092846222\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.19188251043188823\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.19056019150836478\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1892918607963493\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18806851043571382\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1868889530553735\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18575076898110188\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.1846541012815259\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.18359548134071552\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.18257110525756687\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.18157917467847604\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.18061827021401544\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17968680038738688\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1787829989034794\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17790476250733248\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.24122686707749166\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24039220455767019\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2395740950352842\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23877119627199317\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.23798276013388134\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23720797855225878\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2364463339303894\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2356975076951202\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2349603963978904\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.23423521804923972\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.23352012839068131\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.23281198881407889\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.23211301923453764\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.23142342493294427\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2307426806679928\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.23007015964071312\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.22940529762018846\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2287474840290878\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.22809684617209677\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.22745315351666964\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.26283305911540894\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.26113838957243485\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2595222659864581\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.25798494769580566\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2565187200578075\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.25511645092909613\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2537750276200277\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2524889103889108\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2512538054091368\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2500640596256323\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24891701042546002\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24781062372756626\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24674161643337322\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24570693616173603\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.244704200642444\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24373089354571056\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.24278548223707247\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.24186645634107778\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24097378900202238\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24010355675843328\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4224799584118589\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.4196203730603755\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4168557413240592\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4141834116451829\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4115940460795675\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.40908811630389724\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4066584693017583\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4043022847431936\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4020159036193176\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.39978983583774574\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3976276153308165\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3955246190897287\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.39347712599926066\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.39148230502596987\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.38953948199386945\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.38764583066327174\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3857980060711873\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.38399275180448283\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.38222939092462227\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3805054427494558\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5082676991623638\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5044001414094784\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.500754371074767\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.49731836873508695\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.49406761681672234\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4909833335945851\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4880528881294395\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.48526831276310445\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.48261386338965795\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.48007978644808946\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.47765400420112886\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4753273348899564\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.47309313332152075\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.470936367981259\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.46885542711786443\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.4668487066447551\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.46490912101002874\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.46302988192779715\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.46120614237785507\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4594326754661635\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3486355806396616\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.34550617384922283\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3425313223542943\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3396888208011598\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33695648108223275\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33434388714231167\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3318436635672457\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32944922660597487\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32715277006671634\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3249466173280198\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32282093627343966\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.32077472160010184\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31880448729654354\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3169049363953897\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3150752311483138\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31331222741808384\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3116112471586927\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3099672174737366\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3083765098487157\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30683783981015444\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3238905984373077\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3228737643252873\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.32187682611145413\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32089741191045246\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3199331925579525\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31898407851361193\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31805031136223394\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.31712800942613384\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.316219469894295\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.31532400138320293\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3144414658516459\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31357088639421027\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3127116282924932\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3118637482050429\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3110275864650117\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3102026183770254\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.30938748473601974\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3085816981640524\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3077850713114697\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30699749577635727\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.15819969669395814\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1572186475124614\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.15626263721301936\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1553305287769059\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.154418799994677\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.15352613195147824\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.15265209057100718\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.1517963011382571\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1509580673873404\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.1501362458982099\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.14933029552406898\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.14854044017697407\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.14776522726917043\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.14700414234915582\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.14625677504279316\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.14552267357274387\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.14480144540133782\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.14409204148206584\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.14339204837214486\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.1427050278833435\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3593680579405629\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35701412247679487\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3547415903825767\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3525425456603233\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3504103043172262\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3483409249055087\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.346331710728082\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34437913045309465\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3424792830458459\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3406321603691806\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.33883979769182615\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.33709103271581775\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3353839032967001\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.33371647962494644\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.332086534402852\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33049223520765436\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3289351849207103\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.32741071284194145\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3259082420914444\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.32443608650724587\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3976342124919878\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3944258183195588\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39135485631137235\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.38841486274901843\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.38560565461033974\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.38291246020181735\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3803382181444374\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3778700276896914\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3755019800744658\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3732271390639219\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.37103881131639427\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.36893237195178374\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.36690312972729106\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3649427962217223\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3630523151674547\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3612272264640003\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3594643644433239\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3577585685458867\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.35610727659335767\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3545082310824216\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.6834131897164353\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.6757917468545526\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.6687944207344924\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.6623372882404495\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.6564062970017839\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.6509394627724078\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.6458769541149864\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.64117114646152\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.6367840070771262\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.6326876230901715\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.628848211900187\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.6252376887327395\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.6218339934974881\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.6186156540186541\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.6155657728001596\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.6126674602199853\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.6099061143345336\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.6072691174560314\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.6047377365712168\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.6023106895910781\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.25978542361570084\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2581179374989112\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.25651598297324724\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.25497301815464335\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.25348578755315765\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2520502245422993\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.25066288868047476\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24931984759063403\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2480182026750394\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.24675315471789305\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2455248586092968\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24433137661650978\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24316938518016729\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24203627656845422\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24093167142719782\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2398529656581897\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2387983219405011\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2377668633145047\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23675773584041776\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2357695496041434\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.34161457788924043\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3388146018880772\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33615990994539613\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33364397256515094\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3312530727274803\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.32897946180508775\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.326810903845558\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32473953548847123\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32275402191383573\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3208533691494777\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3190326658815337\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.31728603196229355\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31560546418666763\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3139880769464975\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3124263962172431\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31091773649582377\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.30945862089715537\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3080456582344476\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3066710786914957\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.30532581602568154\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21761644259335783\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21565484972511928\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.21377012630684056\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.21195895094491593\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.21021784155607706\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20854229939620345\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.20692979611657103\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20538019909745603\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.20389354993705686\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2024622725777065\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.20108075491437133\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.19974790091116848\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.19846127412336184\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.19721857960908917\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.19601789846594053\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.194857371034281\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19373500323537424\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.19264877486926152\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.19159649205392448\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.1905764156104819\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2280812832034618\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.22727243483210774\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22648747213768972\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.22572483892782774\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2249831343028058\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22426101913900165\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.22355734298681806\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22286989132915097\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2221990631976451\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22154381807728385\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.22090368091171642\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22027804860529082\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21966656012282273\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.21906788556661339\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2184814697394619\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2179066980366462\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2173430260509363\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2167899073551524\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21624653010831849\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.21571268855976372\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.40047367390058375\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3977280327339304\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3951264695312085\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3926603053314764\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.39031575279328423\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3880789771767866\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38594055900575786\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3838920267598366\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3819258823544158\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.38003603840061295\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3782150594592983\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.37645799236880007\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3747570614574215\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.37311087057904935\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3715162284454373\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36997206911845737\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3684764270362805\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3670279826442697\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.36562696779378834\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3642602941094678\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31279407974291723\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3112790007884667\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3098121114371426\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3083912863124627\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3070131101306369\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3056733651328913\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.30436924308610325\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.30309885520511626\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3018605317463875\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.30065324050807496\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2994757663657273\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.29832512747839857\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.29719974257935283\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29609928829993215\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2950210633514403\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.29396178721225297\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2929225496806554\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29190668436967177\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2909090600306298\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2899266940410561\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3051483240287995\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3026682716145497\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.30030161002832245\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2980370658400231\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2958680371047348\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.29378390409683597\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.29178943513885625\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28987397325720576\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.28802741402746246\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2862490853835637\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.28453428821652926\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2828759943644432\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.28127073872559977\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2797156549129056\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.27820820751338166\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27674532740129276\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2753242958662946\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2739427321808236\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.27259808512906564\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2712885175292141\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3914788884852061\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.38770730210008764\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.384192265020718\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.38091871074176525\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3778571281970892\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3749861451249762\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3722905157029792\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.36975064996579393\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3673452746281488\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3650660909051846\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3629009901515013\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3608334979962837\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3588561792853999\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3569643263692334\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3551473580093514\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.35340315362723784\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3517244542075002\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3501081044344705\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.34855026171495096\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.34704217684891064\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.37731037502933346\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3730523944360633\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3690521472056305\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3652870722277409\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3617359473495841\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3583772883067893\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3552011972428847\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3521953530155003\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3493453355480537\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.34663865596633153\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3440655392656603\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.34161840135307614\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3392856400106003\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3370602559384256\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3349322857944041\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.332896616539945\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3309479709707962\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.32908151375465783\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32728989849059964\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3255689398286025\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2933685788455542\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.290613119084138\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2879902119758546\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28549077196935996\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28310597836202567\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.28082911640919617\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.278651199721342\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.27656610238108026\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2745676805020226\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2726498322983719\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.27080752664459645\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.269035960708249\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2673308142953491\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2656885144408512\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.26410811956201796\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.26258755299237524\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2611215527220687\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2596992067651349\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.25832022570890023\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2569819636712135\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.27968072812598527\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.27697055057741926\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.27445161518987693\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.272103166552396\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2699046834790016\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2678482932441469\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.265911185370436\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2640746209544803\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.26234519151571917\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2607141473385025\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2591745441130125\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.25771782969958257\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2563356078935126\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.25502380668976476\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2537721605127693\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.25258036821583774\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2514457677496384\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2503653398379682\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24933083863968292\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24833942063017655\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23066561861270007\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.22790386408978675\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22545678142140613\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2232728344459937\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.22130507016729414\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.21952135797219235\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.21789327530258198\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.21639462740138704\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21500434400978952\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.21370513788194873\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2124833247527278\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2113292332192718\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2102319345916187\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20918548940740703\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20818391469690534\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2072209029329931\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2062900850971649\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.20538769112856017\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2045106296287632\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2036555911845154\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.33335299611407665\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3319901533730952\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33066750432485464\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3293816310042783\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.32813342234245674\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3269186005146415\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3257336782760488\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.324574870712373\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3234413916115522\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3223296861374552\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32124132678742345\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.32017301321695535\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.31912133635987766\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.31808571903762095\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.31706466441437753\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31605557246535965\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3150600054628264\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3140773988237443\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.31310629348401237\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3121482307214154\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21942678217105469\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21764855416659024\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.21594713595341983\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.21431831379813257\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.21275603786923714\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.21125641862583536\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2098152917193288\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20842890953602616\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2070943614458392\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.20580424981269482\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2045440040404919\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.20333053389686792\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2021597436201819\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20102876882696102\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.1999342270290219\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.19887422911297528\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19784691749646138\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.19685102999825593\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.19588452038643928\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.19494729247625403\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3426650806311543\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.34064487489798256\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33869934233520277\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33682402174929704\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.33502332026780735\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33328792871117485\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3316125298370556\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.32999936886068804\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.32843894067482987\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3269287958927718\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32546791919482043\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3240531345156128\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3226843498498264\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3213560391277644\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.32006254086769825\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31880974114517524\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3175998218890128\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3164224982153894\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.31527480863914037\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3141553919812719\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4766006775918417\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.47037798546391996\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.4645679312831126\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4591454230716483\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.4540817758568291\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.449338683762747\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.44489902380152113\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4407221139184885\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.4367900671849877\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4330956466640853\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.42961861732877155\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4263435383572637\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.4232594172219472\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.42034629937316403\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4175891627753783\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.414971677178528\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.4124873827678568\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.410127730251508\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4078794903872233\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4057332963804281\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23443889391983477\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.23356031834748436\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23269471800665242\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23184020750459042\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2309984836038833\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23017044427130762\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.22935373001712106\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.22854797914473163\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2277527881116308\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22696780416681467\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.22619100156360944\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22542513939188666\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.22466832690213911\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22392102916676127\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22318276185540173\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.22245324839527053\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2217321106178589\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.22101905882788792\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2203138653592534\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.219616364856288\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.25115298283803966\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.25017739633273434\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2492276980611543\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2483010043846818\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.24739460283471632\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.24650853957850094\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2456414962771022\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24479217092701502\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.24396313105835052\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.24315028258526408\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24235272307365668\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.24156953968742326\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.24080050286807025\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.24004453480209817\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.23930076164233233\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2385684994915433\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2378475296889599\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23713786868782252\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23643927887473448\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.235750589711498\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.29180661865916485\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2903721865074965\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.28897820337848157\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28762217216783814\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28630321104841683\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.28502050202860074\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2837711405790412\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.28255252812724296\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2813642586906746\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.28020478352666617\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2790679869755062\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2779571429951485\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.27687058259712016\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.27580697579730207\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2747654768699638\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.273746129326557\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2727475504937165\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.27176969733162215\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2708097884804817\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.26986725050425864\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2973057780204952\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2941407403049071\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2911779452032797\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28840591828473433\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28580917318864935\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.28337425983470854\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28108402102656405\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.27892882585277434\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.27689596275002853\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2749777710847968\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2731626361554348\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.27144409389012986\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2698124663753235\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.26826114125348777\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2667834394468149\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.26537336551009916\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.26402570669482844\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.26273574604236866\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2614998807670663\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2603144502562475\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2444235361971985\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24242288311179716\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.24052421410796543\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.23873190118260795\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.23703371055558697\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23541830463383634\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.23388041911955676\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.23241276659485732\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.23100601699527035\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22966129583581102\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.22837041936465335\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22712858859200144\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.22593348623944184\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22477981589202803\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22366441512823307\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.22258898791864995\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.22155133780084676\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.22054209517542028\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21955973682627705\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2186031058971264\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2940989491855553\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.29236361686380186\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.29068576569003435\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.28906585456898515\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.28750423698828054\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2859945818001656\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.28453419088910503\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2831192597174507\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2817443221569933\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.28040630676080985\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.279103072427747\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2778326927188278\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.27659317605421324\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.27538465377957067\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.27420427383907636\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.27304968175530064\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.27191907043703023\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2708118076366995\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.269725666372423\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2686609777313326\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.26067027417220723\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.25743691452306544\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2544303117289105\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.25163102046590013\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.24901925949026857\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.24657515842019206\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.24427973122034144\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24211929987953906\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2400811498447612\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2381541451211569\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.23632701717532245\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.23459145726098207\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.23294253671419632\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.23137036268675987\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22986895238185331\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.228433825566119\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.22705996772217557\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.22574279890244833\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.22447568874380577\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2232565952547354\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.16160685476777137\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1605955410912101\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.15963062113807291\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.15870963973190166\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.15782893055260475\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.1569851019040976\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.15617568861919146\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.15539839066599087\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1546515579864101\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.1539338790379854\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.15324661305123866\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.1525848799276907\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.15194709575787824\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1513301528389856\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.15073250025780274\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.150152974546087\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.14959045207350768\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.14904401472414697\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.14851298654355466\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.1479964742563787\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2244913805666911\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.22286046867295178\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.22128237923788072\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.21975369221109625\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.21827002387211442\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.21683227549343806\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.21543759996598127\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2140829030148262\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.21276642147047625\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.21148780821800134\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21024643010159352\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2090388343752973\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.20786360147575078\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.20671965736040887\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.20560576201772549\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.20452089972461682\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2034642130017981\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.202435509558135\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.20143275237932212\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2004549519725055\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3368468067524222\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3354974416367498\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.33417799782724744\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.33288696969575526\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3316223913236137\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.33038269819959976\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.32916731541511346\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.327972874174956\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3267975556400763\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3256428505487607\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.32450874430194765\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.32339302877477577\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3222951313044453\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.32121300709438666\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.32014839299186715\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.31909983482622717\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.31806296977474136\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.31703589264294124\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.31602059941099636\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3150176071977612\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.23349472727355122\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2317269533231557\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.23004753147289528\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.228449894552255\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2269280501405643\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.22547574661106434\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.224088820907772\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2227623679158365\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.22148918559559333\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.22026582448866294\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.21909139581409776\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.21796300201233373\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.21687746509643988\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.21582995253827492\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.21481804149278766\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.21383965808769295\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21289259168611402\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.21197610869978442\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.211088131735199\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2102260997007813\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3972136932391218\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.39547111286466874\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3937704156282367\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3921096323462542\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.390487344806917\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.38890202724142375\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3873509530468108\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38583072297893173\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38433381659660865\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3828687550707984\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.38143647005345116\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3800313529057102\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3786540254549526\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.37730100862025623\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3759705159197953\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37466406194587326\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.37338040442242626\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.37211910402776893\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3708797632620372\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3696611153188881\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3607715071816819\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.35766180860278896\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.354695509606906\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.351869471973021\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3491689807399316\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3465795514672143\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.34409373498709905\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.34170174903798983\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.33939650608898136\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3371767442874861\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.335035829996094\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3329701897112235\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.33097287042495915\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3290426997387191\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.327173582400364\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.3253613861904577\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.32360326057677957\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.32189704233547045\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32023895879947856\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.31862276242753423\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.18595893224526835\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.18340891080387062\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.18099825845446194\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1787128227229839\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.17654760108775144\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.1744968378317003\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.17255572538993103\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.17071653715163393\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.16897395771751744\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.16731625118675159\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.16573916342565986\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.16423608685623542\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.16279275660070786\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1614175481461474\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.1601044356836615\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1588452044800458\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.15764146091069506\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.15649080114736572\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1553904862821171\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.15433690445460332\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21547021492351645\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2134488990963651\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.21154482182837892\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.20974358238629642\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.20803348531340424\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20641226688641287\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.20487427810183395\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20341332701365233\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.20202302806098282\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.20069864839364693\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.19943506891293836\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.19822683244932476\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.19707048678627107\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.19596321703946692\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.19490203281035137\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1938837756629307\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19290551009595905\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.19196457474942324\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.19105881775759734\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.19018570588464945\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31256910225707024\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.31105713153171477\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.30958918574715755\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.30816286039427504\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3067742744064536\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.3054214854456918\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.30410162386419415\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3028141299927122\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3015594643697306\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3003339377508679\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2991365304945214\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2979719974741712\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.296834431976482\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.295722741552164\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29463140867606247\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2935615976316064\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.29251419630470676\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.29148753625072116\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.29047904038709\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2894881454156477\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.18761440824087094\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1858433990901626\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.18415689027193605\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.18254946406557404\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.18101494240489496\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.17955049320220168\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.17814850938175536\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.17680765490009004\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1755243532696985\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.1742946562500509\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.17311572908189246\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.17198262926444305\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.1708945976013982\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.16984851998744072\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.16884065909405876\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.16787006423549314\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.16693591167411692\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.1660363502413034\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1651691605268542\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.16433302437717962\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.3322088755490359\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.32812401385620416\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3243254221561028\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.32078145016345566\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.31746669118519577\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.31436345888650374\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.31144754674133657\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.30870064806583475\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3061051923295274\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3036486779277031\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.30131892098753504\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.29910476633333466\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2969983917875535\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.29498767478045995\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.29306521320260626\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.29122306353497673\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2894526504562289\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.28775130615539385\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.28611398519058084\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2845358005610042\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.21403954093998104\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21252262038246592\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2110788376771479\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.20970320388042446\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.20838920006930417\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20713230973923794\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2059280372435369\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20477253557647238\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2036623576519508\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.20259131080353154\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2015554208097651\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.20055548900456352\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.19958835190638086\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.19865154947249636\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.19774343327991073\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1968626877595992\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.19600657552163275\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.19517356740121813\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1943622885674004\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.1935712008303359\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.31917493021365234\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3133180186552307\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.3078075057527085\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3026330527215872\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.29779437931580965\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.29324074452878823\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2889593253113257\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2849294089443954\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.281130737988879\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.27755030473531683\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2741696344834151\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.27098367276107316\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.267978947553828\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2651385504751834\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.2624532922077225\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2599119552296389\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2575038701721937\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.25521790632264785\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.2530442232586502\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2509816828946613\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4052422704758356\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.40197737314120563\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.39888450237079687\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.3959489262692548\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3931603868295899\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.390506003052564\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.38797332901758097\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.38555534403332015\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.38324325508816764\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3810296713279603\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.3789115329043074\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3768784927413608\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3749227944564869\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.3730388405964632\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3712204310774547\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.36946186519391244\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3677598720066165\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.36611506258566906\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.36452099822483774\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.36297483345179443\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.29175558211907904\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.2875068305319308\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2834872940641415\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.2796553598534553\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.27603437641000117\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.27261466726127564\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2693762310663974\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.26630775711062166\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.26339728871526236\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.26063548664948155\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2580123320540794\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.25551651861324487\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2531442965915044\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.25088915739457324\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.24873986069547283\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.24668975797128057\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.24473237144043397\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.24285792411301663\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24106229128765894\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2393416564345689\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.25129749827865355\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.24851903300121586\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.24586392897379256\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.24332358289766906\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.24089192173877588\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.23856696836935537\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.23634051393330138\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.23420791413601616\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.23216432981329582\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.23020256025901525\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.22832118992124406\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.22651635212518012\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.22478057521082861\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.22311004071314477\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.22150176798291574\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2199579008766218\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.21846985351578124\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2170341766113011\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.21564686609410064\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.21430745258989214\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2711490637317746\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.26951556320840586\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.2679221032914799\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.26636644976268364\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2648457484049738\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2633592606199203\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.26190516429071237\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.2604819256429734\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2590879855413984\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.2577220024101583\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.2563829331911052\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2550700996531236\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.2537821309535029\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.25251800316602735\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.25127612665407356\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.2500558768280446\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.24885618142454063\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.2476765841421484\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.24651864094397963\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.24538219275831108\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.11847712654021006\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1176840240498969\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.1169077033585439\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.11614771251624373\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.11540377763299417\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.1146744223358819\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.11395952846276268\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.11325926541300253\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.11257320767709128\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.1119008584571167\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.11124233359750925\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.11059722508217741\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.10996506146170582\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.10934525138060444\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.10873760714697733\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.10814183791826691\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.10755805989759502\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.10698537413833645\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.10642253118223338\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.10587005799184418\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.17422318762718886\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1727366455892847\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.17130384091558662\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.16992206109739066\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.16858824373856174\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.1672983223300506\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.16604960815898973\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.16484033234676726\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1636661160937528\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.16252741748437566\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.16142234833811714\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.16034852890037166\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.1593047121950949\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.15828921401232035\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.1573005941101066\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.15633797686555717\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.1553995891495422\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.15448576425968433\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.15359679341008411\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.15272832199776487\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.22214898487561854\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.21900094321102948\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.21598620051680345\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.21310646574346187\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.21034899218888004\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.20770547296175595\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.20517041219550855\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.20273551705120346\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.20039334713115606\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.19813913850695364\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1959679994578758\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.19387687941267617\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.19186114055108755\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1899163176998535\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.18803702374458012\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1862214761802013\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.18446279721592346\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.18275771391499102\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.18110677340246584\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17950658230984962\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.20451968772077309\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.20119758334856294\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19803960557594508\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.19503579524886483\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.19218562264884906\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.18947963072253482\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.18691162300381775\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.18447882291430978\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.18216621014086992\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.17996548297953935\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.17787195379959678\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.1758763446665967\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.17397439203528353\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1721594777108017\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.1704262340096221\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1687694389876616\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.1671860908425043\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.16567319906554095\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.16422611490612637\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.16284090567998982\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19315277512198234\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19187073386650444\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.19064029885452963\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.18945887364840766\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.18832074245410985\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.18722387537041918\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.1861652873806132\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.18514184031790643\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1841510350419012\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.18319191481047398\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.1822614872692666\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.18135866582461302\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.18048337593646668\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.17963279439407798\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.1788045577484942\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.17799780879026542\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.1772118531104218\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.17644564428870757\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.17569839301875198\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.17496921770352147\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.2520144302020323\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.25085788502529804\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.24972369243565357\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.24861186997243734\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.2475211386011063\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.2464506995670243\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.2453999135424076\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.24436936895916722\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.2433581912025957\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.24236408925759556\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.24138627840705962\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.2404245334131813\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.23947894425999752\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.2385526246472336\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.23764027158508502\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.23674221357141556\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.2358568571908377\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.23498392498570903\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.23412116636312957\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.2332706309764835\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.07197197629518623\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.07153121253970643\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.07110165672067288\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.070682164645447\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.07027208608266482\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.06987114931571929\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.06947918703997312\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.0690957598651333\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.06872067379015888\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.06835357899491856\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.06799405588006995\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.06764185860911916\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.0672968814256702\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.0669589080201488\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.06662774268935343\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.06630326189902369\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.06598514336842454\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.06567325463152288\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.06536734634817999\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.06506722228940216\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.0829818661251394\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.08211024432965092\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.08128695655953766\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.08050917240652902\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.07977345845762573\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.07907640895828266\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.078415303773095\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.07778795813968861\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.07719155736237984\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.07662406624048647\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.0760836338165447\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.0755682293882102\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.07507633273502179\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.07460659946417977\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.07415741384471744\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.07372887637375848\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.07331955248824007\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.07292703230920021\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.0725504217680212\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.07218880096682424\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.13056480933087675\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.1275520628609085\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.12473589373323477\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.1221088142667847\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.11965386516649314\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.11735689781045695\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.11520727787930979\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.11319052492224044\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.11129473732195376\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.10950896900039998\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.10782385972183768\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.1062311502681695\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.10472436249049974\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.10329757495966051\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.10194616924734047\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.10066750556785983\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.09945393260942124\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.09829792554540992\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.0971957625405463\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.09614542147880853\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.4849777469590865\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.47390914933009703\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.46374644509743024\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.4543323549438842\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.44561413339672173\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.4375279559855575\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.4300042715536059\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4229868172337634\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.41640906425534074\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.4102126048570031\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4043509895915488\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3987831020092798\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.3934900299105855\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.38844184763141854\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.3836032975111813\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.37895370341258805\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.37446868997931626\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3701404013568345\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.3659645981328167\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.36192572335684864\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.19861803325204214\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.19007679372838782\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.18274156974402297\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.17639657475361\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.1708868268394472\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.16608149147548812\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.1618647490377837\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.15814363965324613\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.1548358449820002\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.15188101280111088\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.14922052553652834\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.14681372661367825\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.14462135287287395\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.1426100548876408\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.14075833021000833\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.1390463602460676\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.13745497527896133\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.13597064117925667\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.1345806721241048\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.13327290332182112\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.1124847652794213\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.11165849046297249\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.11086510897027207\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.11010371575636237\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.10937157996633126\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.10866673734799437\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.10798769971455292\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.10733303861548449\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.10670155676629645\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.10609194480751352\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.10550320630981144\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.10493465409882878\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.10438527397855951\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.10385332773725403\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.10333828061187353\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.10283934697351081\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.10235563188817831\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.10188647028171413\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.10143133958733393\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.10098947144782855\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.5176429811600225\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.5147747936886311\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.5119797672732007\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.509255322969904\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.5065960279033519\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.5039980378104238\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.5014575463864059\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.4989722398712557\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.49653941461162365\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.49415783999973634\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.4918300521437088\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.4895467797191828\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.48730503364059746\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.4851036151642617\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.4829406868219675\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.48081454915008087\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.47872249247018134\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.47665867320111605\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.4746239347620797\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.4726189504497424\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.0690732530065474\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.06852708018954598\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.06800274250484879\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.06749903479231462\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.06701485008304121\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.06654977951466848\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.06610184590279627\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.06567015437827653\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.06525341566687642\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.06485070895234893\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.0644613553201491\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.06408446157393044\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.06371838273976407\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.06336361925243372\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.06301947267690003\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.06268526975592073\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.06236041085831415\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.06204466206183479\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.061737647611322444\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.06143916079111388\n",
      "training epoch: 0\n",
      "epoch: 0 loss: 0.39031597662046363\n",
      "training epoch: 1\n",
      "epoch: 1 loss: 0.3847512552589458\n",
      "training epoch: 2\n",
      "epoch: 2 loss: 0.379538254886381\n",
      "training epoch: 3\n",
      "epoch: 3 loss: 0.37464959875396414\n",
      "training epoch: 4\n",
      "epoch: 4 loss: 0.3700281097463352\n",
      "training epoch: 5\n",
      "epoch: 5 loss: 0.36568336045733335\n",
      "training epoch: 6\n",
      "epoch: 6 loss: 0.3615943624138403\n",
      "training epoch: 7\n",
      "epoch: 7 loss: 0.3577385739558652\n",
      "training epoch: 8\n",
      "epoch: 8 loss: 0.3540806422798202\n",
      "training epoch: 9\n",
      "epoch: 9 loss: 0.3506153381036147\n",
      "training epoch: 10\n",
      "epoch: 10 loss: 0.34733188502542994\n",
      "training epoch: 11\n",
      "epoch: 11 loss: 0.3442179386215709\n",
      "training epoch: 12\n",
      "epoch: 12 loss: 0.34126023571431024\n",
      "training epoch: 13\n",
      "epoch: 13 loss: 0.33844477265118883\n",
      "training epoch: 14\n",
      "epoch: 14 loss: 0.33575928924955983\n",
      "training epoch: 15\n",
      "epoch: 15 loss: 0.33319824056546765\n",
      "training epoch: 16\n",
      "epoch: 16 loss: 0.3307560841437816\n",
      "training epoch: 17\n",
      "epoch: 17 loss: 0.3284230394545455\n",
      "training epoch: 18\n",
      "epoch: 18 loss: 0.32618769043905455\n",
      "training epoch: 19\n",
      "epoch: 19 loss: 0.3240435021261361\n"
     ]
    }
   ],
   "source": [
    "network.full_train(x_train, y_train, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 91.12%\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for i in range(0, len(x_test), 100):\n",
    "    output_batch = network.forward_pass(x_test[i:i+100])\n",
    "    score += np.sum(np.argmax(output_batch, axis=1) == np.argmax(y_test[i:i+100], axis=1))\n",
    "print(f\"accuracy: {score*100/len(x_test)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
